<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Linux on </title>
    <link>https://feilengcui008.github.io/categories/linux/</link>
    <description>Recent content in Linux on </description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 09 Oct 2017 11:41:42 +0800</lastBuildDate>
    <atom:link href="https://feilengcui008.github.io/categories/linux/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Linux内核栈与thread_info</title>
      <link>https://feilengcui008.github.io/post/linux%E5%86%85%E6%A0%B8%E6%A0%88/</link>
      <pubDate>Mon, 09 Oct 2017 11:41:42 +0800</pubDate>
      <guid>https://feilengcui008.github.io/post/linux%E5%86%85%E6%A0%B8%E6%A0%88/</guid>
      <description>&lt;h2 id=&#34;内核栈与thread_info&#34;&gt;内核栈与thread_info&lt;/h2&gt;&#xA;&lt;p&gt;Linux内核在x86平台下，PAGE_SIZE为4KB(32位和64位相同)，THREAD_SIZE为8KB(32位)或者16KB(64位)。THREAD_SIZE表示了整个内核栈的大小，栈可以向下增长(栈低在高地址)或者向上增长(栈低在低地址)，后面的分析都是基于向下增长的方式。如图中所示，整个内核栈可分为四个部分，从低地址开始依次为:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;thread_info结构体&lt;/li&gt;&#xA;&lt;li&gt;溢出标志&lt;/li&gt;&#xA;&lt;li&gt;从溢出标志开始到kernel_stack之间的实际可用栈内存空间，kernel_stack为percpu变量，通过它可间接找到内核栈的起始地址&lt;/li&gt;&#xA;&lt;li&gt;从kernel_stack到栈底的长度为KERNEL_STACK_OFFSET的保留空间&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://feilengcui008.github.io/images/kernel_stack.jpg&#34; alt=&#34;kernel_stack&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;内核引入thread_info的一大原因是方便通过它直接找到进(线)程的task_struct指针，x86 平台的thread_info结构体定义在arch/x86/include/asm/thread_info.h。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// Linux 3.19.3 x86平台的thread_info&#xA;struct thread_info {&#xA;&#x9;struct task_struct&#x9;*task;&#x9;&#x9;/* main task structure */&#xA;&#x9;struct exec_domain&#x9;*exec_domain;&#x9;/* execution domain */&#xA;&#x9;__u32&#x9;&#x9;&#x9;flags;&#x9;&#x9;/* low level flags */&#xA;&#x9;__u32&#x9;&#x9;&#x9;status;&#x9;&#x9;/* thread synchronous flags */&#xA;&#x9;__u32&#x9;&#x9;&#x9;cpu;&#x9;&#x9;/* current CPU */&#xA;&#x9;int&#x9;&#x9;&#x9;saved_preempt_count;&#xA;&#x9;mm_segment_t&#x9;&#x9;addr_limit;&#xA;&#x9;void __user&#x9;&#x9;*sysenter_return;&#xA;&#x9;unsigned int&#x9;&#x9;sig_on_uaccess_error:1;&#xA;&#x9;unsigned int&#x9;&#x9;uaccess_err:1;&#x9;/* uaccess failed */&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;由于thread_info结构体恰好位于内核栈的低地址开始处，所以只要知道内核栈的起始地址，就可以通过其得到thread_info，进而得到task_struct，后面会分析这个过程的实现。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;current宏&#34;&gt;current宏&lt;/h2&gt;&#xA;&lt;p&gt;current宏在Linux 内核中负责获取当前cpu上的task_struct，通常是借助thread_info和内核栈实现，这种方式的主要逻辑是:&lt;/p&gt;</description>
    </item>
    <item>
      <title>ABI</title>
      <link>https://feilengcui008.github.io/post/abi/</link>
      <pubDate>Thu, 21 Sep 2017 16:32:02 +0800</pubDate>
      <guid>https://feilengcui008.github.io/post/abi/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Application_binary_interface&#34;&gt;ABI&lt;/a&gt;指应用二进制接口，规定了二进制程序两个模块之间或者二进制程序与操作系统之间的接口，这里主要关注&lt;a href=&#34;https://en.wikipedia.org/wiki/Calling_convention&#34;&gt;调用规范call convention&lt;/a&gt;。不同的体系结构、操作系统、编程语言、每种编程语言的不同编译器实现基本都有自己规定或者遵循的ABI和调用规范。另外，也可通过&lt;a href=&#34;https://en.wikipedia.org/wiki/Foreign_function_interface&#34;&gt;FFI&lt;/a&gt;规范实现跨编程语言的过程调用，比如Python/Java/Go等提供了C的FFI，这样通过C实现互相调用。&lt;/p&gt;&#xA;&lt;p&gt;Linux在x86_64和i386下的ABI:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/X86_calling_conventions&#34;&gt;x86下的调用规范&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/2535989/what-are-the-calling-conventions-for-unix-linux-system-calls-on-x86-64&#34;&gt;Linux i386 and x86_64 call convention&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://refspecs.linuxfoundation.org/elf/x86_64-abi-0.99.pdf&#34;&gt;x86_64下用户态程序和系统调用ABI&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://refspecs.linuxfoundation.org/elf/abi386-4.pdf&#34;&gt;i386下用户态和系统调用ABI&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这里就不详细解释不同的ABI和调用规范了，可以通过简单的C/C++程序和内核代码分别验证用户态和系统调用的规范。另外，对于类似Go语言有自己的一套函数&lt;a href=&#34;https://github.com/golang/go/issues/16922&#34;&gt;调用规范&lt;/a&gt;的，也可以通过生成的汇编去验证。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linux内核抢占</title>
      <link>https://feilengcui008.github.io/post/linux%E5%86%85%E6%A0%B8%E6%8A%A2%E5%8D%A0/</link>
      <pubDate>Sat, 18 Jun 2016 11:02:55 +0800</pubDate>
      <guid>https://feilengcui008.github.io/post/linux%E5%86%85%E6%A0%B8%E6%8A%A2%E5%8D%A0/</guid>
      <description>&lt;p&gt;本文主要介绍内核抢占的相关概念和具体实现，以及抢占对内核调度、内核竞态和同步的一些影响。(所用内核版本3.19.3)&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h4 id=&#34;1-基本概念&#34;&gt;1. 基本概念&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;用户抢占和内核抢占&#xA;&lt;ul&gt;&#xA;&lt;li&gt;用户抢占发生点&#xA;&lt;ul&gt;&#xA;&lt;li&gt;当从系统调用或者中断上下文返回用户态的时候，会检查need_resched标志，如果被设置则会重新选择用户态task执行&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;内核抢占发生点&#xA;&lt;ul&gt;&#xA;&lt;li&gt;当从中断上下文返回内核态的时候，检查need_resched标识以及__preemp_count计数，如果标识被设置，并且可抢占，则会触发调度程序preempt_schedule_irq()&lt;/li&gt;&#xA;&lt;li&gt;内核代码由于阻塞等原因直接或间接显示调用schedule，比如preemp_disable时可能会触发preempt_schedule()&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;本质上内核态中的task是共享一个内核地址空间，在同一个core上，从中断返回的task很可能执行和被抢占的task相同的代码，并且两者同时等待各自的资源释放，也可能两者修改同一共享变量，所以会造成死锁或者竞态等；而对于用户态抢占来说，由于每个用户态进程都有独立的地址空间，所以在从内核代码(系统调用或者中断)返回用户态时，由于是不同地址空间的锁或者共享变量，所以不会出现不同地址空间之间的死锁或者竞态，也就没必要检查__preempt_count，是安全的。__preempt_count主要负责内核抢占计数。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h4 id=&#34;2-内核抢占的实现&#34;&gt;2. 内核抢占的实现&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;percpu变量__preempt_count&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;抢占计数8位, PREEMPT_MASK                     =&amp;gt; 0x000000ff&#xA;软中断计数8位, SOFTIRQ_MASK                   =&amp;gt; 0x0000ff00&#xA;硬中断计数4位, HARDIRQ_MASK                   =&amp;gt; 0x000f0000&#xA;不可屏蔽中断1位, NMI_MASK                     =&amp;gt; 0x00100000&#xA;PREEMPTIVE_ACTIVE(标识内核抢占触发的schedule)  =&amp;gt; 0x00200000&#xA;调度标识1位, PREEMPT_NEED_RESCHED             =&amp;gt; 0x80000000&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;__preempt_count的作用&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;抢占计数&lt;/li&gt;&#xA;&lt;li&gt;判断当前所在上下文&lt;/li&gt;&#xA;&lt;li&gt;重新调度标识&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;thread_info的flags&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;thread_info的flags中有一个是TIF_NEED_RESCHED，在系统调用返回，中断返回，以及preempt_disable的时候会检查是否设置，如果设置并且抢占计数为0(可抢占)，则会触发重新调度schedule()或者preempt_schedule()或者preempt_schedule_irq()。通常在scheduler_tick中会检查是否设置此标识(每个HZ触发一次)，然后在下一次中断返回时检查，如果设置将触发重新调度，而在schedule()中会清除此标识。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// kernel/sched/core.c&#xA;// 设置thread_info flags和__preempt_count的need_resched标识&#xA;void resched_curr(struct rq *rq)&#xA;{&#xA;  /*省略*/&#xA;    if (cpu == smp_processor_id()) {&#xA;    // 设置thread_info的need_resched标识 &#xA;    set_tsk_need_resched(curr);&#xA;    // 设置抢占计数__preempt_count里的need_resched标识&#xA;    set_preempt_need_resched();&#xA;    return;&#xA;  }&#xA;  /*省略*/&#xA;}&#xA;  &#xA;//在schedule()中清除thread_info和__preempt_count中的need_resched标识&#xA;static void __sched __schedule(void)&#xA;{&#xA;  /*省略*/&#xA;need_resched:&#xA;  // 关抢占读取percpu变量中当前cpu id，运行队列&#xA;  preempt_disable();&#xA;  cpu = smp_processor_id(); &#xA;  rq = cpu_rq(cpu);&#xA;  rcu_note_context_switch();&#xA;  prev = rq-&amp;gt;curr;&#xA;  /*省略*/&#xA;    //关闭本地中断，关闭抢占，获取rq自旋锁&#xA;  raw_spin_lock_irq(&amp;amp;rq-&amp;gt;lock);&#xA;  switch_count = &amp;amp;prev-&amp;gt;nivcsw;&#xA;  // PREEMPT_ACTIVE 0x00200000&#xA;  // preempt_count = __preempt_count &amp;amp; (~(0x80000000))&#xA;  // 如果进程没有处于running的状态或者设置了PREEMPT_ACTIVE标识&#xA;  //(即本次schedule是由于内核抢占导致)，则不会将当前进程移出队列&#xA;  // 此处PREEMPT_ACTIVE的标识是由中断返回内核空间时调用&#xA;  // preempt_schdule_irq或者内核空间调用preempt_schedule&#xA;  // 而设置的，表明是由于内核抢占导致的schedule，此时不会将当前&#xA;  // 进程从运行队列取出，因为有可能其再也无法重新运行。&#xA;  if (prev-&amp;gt;state &amp;amp;&amp;amp; !(preempt_count() &amp;amp; PREEMPT_ACTIVE)) {&#xA;    // 如果有信号不移出run_queue&#xA;    if (unlikely(signal_pending_state(prev-&amp;gt;state, prev))) {&#xA;      prev-&amp;gt;state = TASK_RUNNING;&#xA;    } else { // 否则移除队列让其睡眠&#xA;      deactivate_task(rq, prev, DEQUEUE_SLEEP);&#xA;      prev-&amp;gt;on_rq = 0;&#xA;      // 是否唤醒一个工作队列内核线程&#xA;      if (prev-&amp;gt;flags &amp;amp; PF_WQ_WORKER) {&#xA;        struct task_struct *to_wakeup;&#xA;&#xA;        to_wakeup = wq_worker_sleeping(prev, cpu);&#xA;        if (to_wakeup)&#xA;          try_to_wake_up_local(to_wakeup);&#xA;      }&#xA;    }&#xA;    switch_count = &amp;amp;prev-&amp;gt;nvcsw;&#xA;  }&#xA;    /*省略*/&#xA;  next = pick_next_task(rq, prev);&#xA;  // 清除之前task的need_resched标识&#xA;  clear_tsk_need_resched(prev);&#xA;    // 清除抢占计数的need_resched标识&#xA;  clear_preempt_need_resched();&#xA;  rq-&amp;gt;skip_clock_update = 0;&#xA;  // 不是当前进程，切换上下文&#xA;  if (likely(prev != next)) {&#xA;    rq-&amp;gt;nr_switches++;&#xA;    rq-&amp;gt;curr = next;&#xA;    ++*switch_count;&#xA;    rq = context_switch(rq, prev, next);&#xA;    cpu = cpu_of(rq);&#xA;  } else&#xA;    raw_spin_unlock_irq(&amp;amp;rq-&amp;gt;lock);&#xA;  post_schedule(rq);&#xA;  // 重新开抢占&#xA;  sched_preempt_enable_no_resched();&#xA;  // 再次检查need_resched&#xA;  if (need_resched())&#xA;    goto need_resched;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;__preempt_count的相关操作&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&#xA;/////// need_resched标识相关 ///////&#xA;&#xA;// PREEMPT_NEED_RESCHED位如果是0表示需要调度&#xA;#define PREEMPT_NEED_RESCHED 0x80000000 &#xA;&#xA;static __always_inline void set_preempt_need_resched(void)&#xA;{&#xA;  // __preempt_count最高位清零表示need_resched&#xA;  raw_cpu_and_4(__preempt_count, ~PREEMPT_NEED_RESCHED);&#xA;}&#xA;&#xA;static __always_inline void clear_preempt_need_resched(void)&#xA;{&#xA;  // __preempt_count最高位置位&#xA;  raw_cpu_or_4(__preempt_count, PREEMPT_NEED_RESCHED);&#xA;}&#xA;&#xA;static __always_inline bool test_preempt_need_resched(void)&#xA;{&#xA;  return !(raw_cpu_read_4(__preempt_count) &amp;amp; PREEMPT_NEED_RESCHED);&#xA;}&#xA;&#xA;// 是否需要重新调度，两个条件：1. 抢占计数为0；2. 最高位清零&#xA;static __always_inline bool should_resched(void)&#xA;{&#xA;  return unlikely(!raw_cpu_read_4(__preempt_count));&#xA;}&#xA;&#xA;////////// 抢占计数相关 ////////&#xA;&#xA;#define PREEMPT_ENABLED (0 + PREEMPT_NEED_RESCHED)&#xA;#define PREEMPT_DISABLE (1 + PREEMPT_ENABLED)&#xA;// 读取__preempt_count，忽略need_resched标识位&#xA;static __always_inline int preempt_count(void)&#xA;{&#xA;  return raw_cpu_read_4(__preempt_count) &amp;amp; ~PREEMPT_NEED_RESCHED;&#xA;}&#xA;static __always_inline void __preempt_count_add(int val)&#xA;{&#xA;  raw_cpu_add_4(__preempt_count, val);&#xA;}&#xA;static __always_inline void __preempt_count_sub(int val)&#xA;{&#xA;  raw_cpu_add_4(__preempt_count, -val);&#xA;}&#xA;// 抢占计数加1关闭抢占&#xA;#define preempt_disable() \&#xA;do { \&#xA;  preempt_count_inc(); \&#xA;  barrier(); \&#xA;} while (0)&#xA;// 重新开启抢占，并测试是否需要重新调度&#xA;#define preempt_enable() \&#xA;do { \&#xA;  barrier(); \&#xA;  if (unlikely(preempt_count_dec_and_test())) \&#xA;    __preempt_schedule(); \&#xA;} while (0)&#xA;&#xA;// 抢占并重新调度&#xA;// 这里设置PREEMPT_ACTIVE会对schdule()中的行为有影响&#xA;asmlinkage __visible void __sched notrace preempt_schedule(void)&#xA;{&#xA;  // 如果抢占计数不为0或者没有开中断，则不调度&#xA;  if (likely(!preemptible()))&#xA;    return;&#xA;  do {&#xA;    __preempt_count_add(PREEMPT_ACTIVE);&#xA;    __schedule();&#xA;    __preempt_count_sub(PREEMPT_ACTIVE);&#xA;    barrier();&#xA;  } while (need_resched());&#xA;}&#xA;// 检查thread_info flags&#xA;static __always_inline bool need_resched(void)&#xA;{&#xA;  return unlikely(tif_need_resched());&#xA;}&#xA;&#xA;////// 中断相关 ////////&#xA;&#xA;// 硬件中断计数&#xA;#define hardirq_count() (preempt_count() &amp;amp; HARDIRQ_MASK)&#xA;// 软中断计数&#xA;#define softirq_count() (preempt_count() &amp;amp; SOFTIRQ_MASK)&#xA;// 中断计数&#xA;#define irq_count() (preempt_count() &amp;amp; (HARDIRQ_MASK | SOFTIRQ_MASK \&#xA;         | NMI_MASK))&#xA;// 是否处于外部中断上下文&#xA;#define in_irq()    (hardirq_count())&#xA;// 是否处于软中断上下文&#xA;#define in_softirq()    (softirq_count())&#xA;// 是否处于中断上下文&#xA;#define in_interrupt()    (irq_count())&#xA;#define in_serving_softirq()  (softirq_count() &amp;amp; SOFTIRQ_OFFSET)&#xA;&#xA;// 是否处于不可屏蔽中断环境&#xA;#define in_nmi()  (preempt_count() &amp;amp; NMI_MASK)&#xA;&#xA;// 是否可抢占 : 抢占计数为0并且没有处在关闭抢占的环境中&#xA;# define preemptible()  (preempt_count() == 0 &amp;amp;&amp;amp; !irqs_disabled())&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;&#xA;&lt;h4 id=&#34;3-系统调用和中断处理流程的实现以及抢占的影响&#34;&gt;3. 系统调用和中断处理流程的实现以及抢占的影响&lt;/h4&gt;&#xA;&lt;p&gt;(arch/x86/kernel/entry_64.S)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linux内核namespace</title>
      <link>https://feilengcui008.github.io/post/linux%E5%86%85%E6%A0%B8namespace/</link>
      <pubDate>Fri, 10 Jun 2016 19:27:52 +0800</pubDate>
      <guid>https://feilengcui008.github.io/post/linux%E5%86%85%E6%A0%B8namespace/</guid>
      <description>&lt;h3 id=&#34;1-介绍&#34;&gt;1. 介绍&lt;/h3&gt;&#xA;&lt;p&gt;Namespace是Linux内核为容器技术提供的基础设施之一(另一个是cgroups)，包括uts/user/pid/mnt/ipc/net六个(3.13.0的内核)，主要用来做资源的隔离，本质上是全局资源的映射，映射之间独立了自然隔离了。主要涉及到的接口是:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;clone&lt;/li&gt;&#xA;&lt;li&gt;setns&lt;/li&gt;&#xA;&lt;li&gt;unshare&lt;/li&gt;&#xA;&lt;li&gt;/proc/pid/ns, /proc/pid/uid_map, /proc/pid/gid_map等&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;后面会简单分析一下内核源码里面是怎么实现这几个namespace的，并以几个简单系统调用为例，看看namespace是怎么产生影响的，最后简单分析下setns和unshare的实现。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;2-测试流程及代码&#34;&gt;2. 测试流程及代码&lt;/h3&gt;&#xA;&lt;p&gt;下面是一些简单的例子，主要测试uts/pid/user/mnt四个namespace的效果，测试代码主要用到三个进程，一个是clone系统调用执行/bin/bash后的进程，也是生成新的子namespace的初始进程，然后是打开/proc/pid/ns下的namespace链接文件，用setns将第二个可执行文件的进程加入/bin/bash的进程的namespace(容器)，并让其fork出一个子进程，测试pid namespace的差异。值得注意的几个点:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;不同版本的内核setns和unshare对namespace的支持不一样，较老的内核可能只支持ipc/net/uts三个namespace&lt;/li&gt;&#xA;&lt;li&gt;某个进程创建后其pid namespace就固定了，使用setns和unshare改变后，其本身的pid namespace不会改变，只有fork出的子进程的pid namespace改变(改变的是每个进程的nsproxy-&amp;gt;pid_namespace_for_children)&lt;/li&gt;&#xA;&lt;li&gt;用setns添加mnt namespace应该放在其他namespace之后，否则可能出现无法打开/proc/pid/ns/&amp;hellip;的错误&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// 代码1: 开一些新的namespace(启动新容器)&#xA;#define _GNU_SOURCE&#xA;#include &amp;lt;sys/wait.h&amp;gt;&#xA;#include &amp;lt;sched.h&amp;gt;&#xA;#include &amp;lt;string.h&amp;gt;&#xA;#include &amp;lt;stdio.h&amp;gt;&#xA;#include &amp;lt;stdlib.h&amp;gt;&#xA;#include &amp;lt;unistd.h&amp;gt;&#xA;&#xA;#define errExit(msg)  do { perror(msg); exit(EXIT_FAILURE); \&#xA;} while (0)&#xA;&#xA;/* Start function for cloned child */&#xA;static int childFunc(void *arg)&#xA;{&#xA;  const char *binary = &amp;#34;/bin/bash&amp;#34;;&#xA;  char *const argv[] = {&#xA;    &amp;#34;/bin/bash&amp;#34;,&#xA;    NULL&#xA;  };&#xA;  char *const envp[] = { NULL };&#xA;&#xA;  /* wrappers for execve */&#xA;  // has const char * as argument list&#xA;  // execl &#xA;  // execle  =&amp;gt; has envp&#xA;  // execlp  =&amp;gt; need search PATH &#xA;  &#xA;  // has char *const arr[] as argument list &#xA;  // execv &#xA;  // execvpe =&amp;gt; need search PATH and has envp&#xA;  // execvp  =&amp;gt; need search PATH &#xA;  &#xA;  //int ret = execve(binary, argv, envp);&#xA;  int ret = execv(binary, argv);&#xA;  if (ret &amp;lt; 0) {&#xA;    errExit(&amp;#34;execve error&amp;#34;);&#xA;  }&#xA;  return ret;&#xA;}&#xA;&#xA;#define STACK_SIZE (1024 * 1024)    /* Stack size for cloned child */&#xA;&#xA;int main(int argc, char *argv[])&#xA;{&#xA;  char *stack; &#xA;  char *stackTop;                 &#xA;  pid_t pid;&#xA;  stack = malloc(STACK_SIZE);&#xA;  if (stack == NULL)&#xA;    errExit(&amp;#34;malloc&amp;#34;);&#xA;  stackTop = stack + STACK_SIZE;  /* Assume stack grows downward */&#xA;&#xA;  //pid = clone(childFunc, stackTop, CLONE_NEWUTS | CLONE_NEWNS | CLONE_NEWPID | CLONE_NEWUSER | SIGCHLD, NULL);&#xA;  pid = clone(childFunc, stackTop, CLONE_NEWUTS | CLONE_NEWNS | CLONE_NEWPID | CLONE_NEWUSER | CLONE_NEWIPC | SIGCHLD, NULL);&#xA;//pid = clone(childFunc, stackTop, CLONE_NEWUTS | //CLONE_NEWNS | CLONE_NEWPID | CLONE_NEWUSER | CLONE_NEWIPC //| CLONE_NEWNET | SIGCHLD, NULL);&#xA;  if (pid == -1)&#xA;    errExit(&amp;#34;clone&amp;#34;);&#xA;  printf(&amp;#34;clone() returned %ld\n&amp;#34;, (long) pid);&#xA;&#xA;  if (waitpid(pid, NULL, 0) == -1)  &#xA;    errExit(&amp;#34;waitpid&amp;#34;);&#xA;  printf(&amp;#34;child has terminated\n&amp;#34;);&#xA;&#xA;  exit(EXIT_SUCCESS);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// 代码2: 使用setns加入新进程&#xA;#define _GNU_SOURCE  // ?&#xA;#include &amp;lt;stdio.h&amp;gt;&#xA;#include &amp;lt;string.h&amp;gt;&#xA;#include &amp;lt;stdlib.h&amp;gt;&#xA;#include &amp;lt;errno.h&amp;gt;&#xA;#include &amp;lt;sys/utsname.h&amp;gt;&#xA;#include &amp;lt;unistd.h&amp;gt;&#xA;#include &amp;lt;sys/types.h&amp;gt;&#xA;#include &amp;lt;sched.h&amp;gt;&#xA;#include &amp;lt;fcntl.h&amp;gt;&#xA;#include &amp;lt;wait.h&amp;gt;&#xA;&#xA;// mainly setns and unshare system calls&#xA;&#xA;/* int setns(int fd, int nstype); */&#xA;&#xA;// 不同版本内核/proc/pid/ns下namespace文件情况&#xA;/*&#xA;   CLONE_NEWCGROUP (since Linux 4.6)&#xA;   fd must refer to a cgroup namespace.&#xA;&#xA;   CLONE_NEWIPC (since Linux 3.0)&#xA;   fd must refer to an IPC namespace.&#xA;&#xA;   CLONE_NEWNET (since Linux 3.0)&#xA;   fd must refer to a network namespace.&#xA;&#xA;   CLONE_NEWNS (since Linux 3.8)&#xA;   fd must refer to a mount namespace.&#xA;&#xA;   CLONE_NEWPID (since Linux 3.8)&#xA;   fd must refer to a descendant PID namespace.&#xA;&#xA;   CLONE_NEWUSER (since Linux 3.8)&#xA;   fd must refer to a user namespace.&#xA;&#xA;   CLONE_NEWUTS (since Linux 3.0)&#xA;   fd must refer to a UTS namespace.&#xA;   */&#xA;&#xA;/* // 特殊的pid namespace &#xA;   CLONE_NEWPID behaves somewhat differently from the other nstype&#xA;values: reassociating the calling thread with a PID namespace changes&#xA;only the PID namespace that child processes of the caller will be&#xA;created in; it does not change the PID namespace of the caller&#xA;itself.  Reassociating with a PID namespace is allowed only if the&#xA;PID namespace specified by fd is a descendant (child, grandchild,&#xA;etc.)  of the PID namespace of the caller.  For further details on&#xA;PID namespaces, see pid_namespaces(7).&#xA;*/&#xA;&#xA;&#xA;/*&#xA;int unshare(int flags);&#xA;CLONE_FILES | CLONE_FS | CLONE_NEWCGROUP | CLONE_NEWIPC | CLONE_NEWNET &#xA;| CLONE_NEWNS | CLONE_NEWPID | CLONE_NEWUSER | CLONE_NEWUTS | CLONE_SYSVSEM&#xA;*/&#xA;&#xA;&#xA;&#xA;#define MAX_PROCPATH_LEN 1024&#xA;&#xA;#define errorExit(msg) \&#xA;  do { fprintf(stderr, &amp;#34;%s in file %s in line %d\n&amp;#34;, msg, __FILE__, __LINE__);\&#xA;    exit(EXIT_FAILURE); } while (0)&#xA;&#xA;void printInfo();&#xA;int openAndSetns(const char *path);&#xA;&#xA;int main(int argc, char *argv[])&#xA;{&#xA;  if (argc &amp;lt; 2) {&#xA;    fprintf(stdout, &amp;#34;usage : execname pid(find namespaces of this process)\n&amp;#34;);&#xA;    return 0;&#xA;  }&#xA;  printInfo();&#xA;&#xA;  fprintf(stdout, &amp;#34;---- setns for uts ----\n&amp;#34;);&#xA;  char uts[MAX_PROCPATH_LEN];&#xA;  snprintf(uts, MAX_PROCPATH_LEN, &amp;#34;/proc/%s/ns/uts&amp;#34;, argv[1]);&#xA;  openAndSetns(uts);&#xA;  printInfo();&#xA;&#xA;  fprintf(stdout, &amp;#34;---- setns for user ----\n&amp;#34;);&#xA;  char user[MAX_PROCPATH_LEN];&#xA;  snprintf(user, MAX_PROCPATH_LEN, &amp;#34;/proc/%s/ns/user&amp;#34;, argv[1]);&#xA;  openAndSetns(user);&#xA;  printInfo();&#xA;&#xA;  // 注意pid namespace的不同行为，只有后续创建的子进程进入setns设置&#xA;  // 的新的pid namespace，本进程不会改变&#xA;  fprintf(stdout, &amp;#34;---- setns for pid ----\n&amp;#34;);&#xA;  char pidpath[MAX_PROCPATH_LEN];&#xA;  snprintf(pidpath, MAX_PROCPATH_LEN, &amp;#34;/proc/%s/ns/pid&amp;#34;, argv[1]);&#xA;  openAndSetns(pidpath);&#xA;  printInfo();&#xA;&#xA;&#xA;  fprintf(stdout, &amp;#34;---- setns for ipc ----\n&amp;#34;);&#xA;  char ipc[MAX_PROCPATH_LEN];&#xA;  snprintf(ipc, MAX_PROCPATH_LEN, &amp;#34;/proc/%s/ns/ipc&amp;#34;, argv[1]);&#xA;  openAndSetns(ipc);&#xA;  printInfo();&#xA;&#xA;  fprintf(stdout, &amp;#34;---- setns for net ----\n&amp;#34;);&#xA;  char net[MAX_PROCPATH_LEN];&#xA;  snprintf(net, MAX_PROCPATH_LEN, &amp;#34;/proc/%s/ns/net&amp;#34;, argv[1]);&#xA;  openAndSetns(net);&#xA;  printInfo();&#xA;&#xA;  // 注意mnt namespace需要放在其他后面，避免mnt namespace改变后&#xA;  // 找不到/proc/pid/ns下的文件&#xA;  fprintf(stdout, &amp;#34;---- setns for mount ----\n&amp;#34;);&#xA;  char mount[MAX_PROCPATH_LEN];&#xA;  snprintf(mount, MAX_PROCPATH_LEN, &amp;#34;/proc/%s/ns/mnt&amp;#34;, argv[1]);&#xA;  openAndSetns(mount);&#xA;  printInfo();&#xA;&#xA;  // 测试子进程的pid namespace&#xA;  int ret = fork();&#xA;  if (-1 == ret) {&#xA;    errorExit(&amp;#34;failed to fork&amp;#34;);&#xA;  } else if (ret == 0) {&#xA;    fprintf(stdout, &amp;#34;********\n&amp;#34;);&#xA;    fprintf(stdout, &amp;#34;in child process\n&amp;#34;);&#xA;    printInfo();&#xA;    fprintf(stdout, &amp;#34;********\n&amp;#34;);&#xA;    for (;;) {&#xA;      sleep(5);&#xA;    }&#xA;  } else {&#xA;    fprintf(stdout, &amp;#34;child pid : %d\n&amp;#34;, ret);&#xA;  }&#xA;  for (;;) {&#xA;    sleep(5);&#xA;  }&#xA;  waitpid(ret, NULL, 0);&#xA;  return 0;&#xA;}&#xA;&#xA;void printInfo()&#xA;{&#xA;  pid_t pid;&#xA;  struct utsname uts;&#xA;  uid_t uid;&#xA;  gid_t gid;&#xA;  // pid namespace &#xA;  pid = getpid();&#xA;  // user namespace &#xA;  uid = getuid();&#xA;  gid = getgid();&#xA;  // uts namespace &#xA;  uname(&amp;amp;uts);&#xA;  fprintf(stdout, &amp;#34;pid : %d\n&amp;#34;, pid);&#xA;  fprintf(stdout, &amp;#34;uid : %d\n&amp;#34;, uid);&#xA;  fprintf(stdout, &amp;#34;gid : %d\n&amp;#34;, gid);&#xA;  fprintf(stdout, &amp;#34;hostname : %s\n&amp;#34;, uts.nodename);&#xA;}&#xA;&#xA;int openAndSetns(const char *path)&#xA;{&#xA;  int ret = open(path, O_RDONLY, 0);&#xA;  if (-1 == ret) {&#xA;    fprintf(stderr, &amp;#34;%s\n&amp;#34;, strerror(errno));&#xA;    errorExit(&amp;#34;failed to open fd&amp;#34;);&#xA;  }&#xA;  if (-1 == (ret = setns(ret, 0))) {&#xA;    fprintf(stderr, &amp;#34;%s\n&amp;#34;, strerror(errno));&#xA;    errorExit(&amp;#34;failed to setns&amp;#34;);&#xA;  }&#xA;  return ret;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;&#xA;&lt;h3 id=&#34;3-测试效果&#34;&gt;3. 测试效果&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;user的效果 : 通过/proc/pid/uid_map和/proc/pid/gid_map设置container外用户id和容器内用户id的映射关系(把这放前面是因为后面hostname和mount需要权限&amp;hellip;)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://img.blog.csdn.net/20160610195657440&#34; alt=&#34;这里写图片描述&#34;&gt;&#xA;&lt;img src=&#34;http://img.blog.csdn.net/20160610195625033&#34; alt=&#34;这里写图片描述&#34;&gt;&#xA;&lt;img src=&#34;http://img.blog.csdn.net/20160610195759722&#34; alt=&#34;这里写图片描述&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linux下的时间</title>
      <link>https://feilengcui008.github.io/post/linux%E4%B8%8B%E7%9A%84%E6%97%B6%E9%97%B4/</link>
      <pubDate>Mon, 16 May 2016 17:03:34 +0800</pubDate>
      <guid>https://feilengcui008.github.io/post/linux%E4%B8%8B%E7%9A%84%E6%97%B6%E9%97%B4/</guid>
      <description>&lt;h3 id=&#34;时钟&#34;&gt;时钟&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;硬件时钟&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;RTC(real time clock)，记录wall clock time，硬件对应到/dev/rtc设备文件，读取设备文件可得到硬件时间&lt;/li&gt;&#xA;&lt;li&gt;读取方式&#xA;&lt;ul&gt;&#xA;&lt;li&gt;通过ioctl&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#include &amp;lt;linux/rtc.h&amp;gt;&#xA;int ioctl(fd, RTC_request, param);&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;li&gt;hwclock命令&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;通常内核在boot以及从低电量中恢复时，会读取RTC更新system time&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;软件时钟&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;HZ and jiffies, 由内核维护，对于PC通常HZ配置为 1s / 10ms = 100&lt;/li&gt;&#xA;&lt;li&gt;精度影响select等依赖timeout的系统调用&lt;/li&gt;&#xA;&lt;li&gt;HRT(high-resolution timers). Linux 2.6.21开始，内核支持高精度定时器，不受内核jiffy限制，可以达到硬件时钟的精度。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;外部时钟&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;从网络ntp，原子钟等同步&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;时间&#34;&gt;时间&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;时间类别&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;wall clock time =&amp;gt; 硬件时间&lt;/li&gt;&#xA;&lt;li&gt;real time =&amp;gt; 从某个时间点(比如Epoch)开始的系统时间&lt;/li&gt;&#xA;&lt;li&gt;sys and user time =&amp;gt; 通常指程序在内核态和用户态花的时间&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;时间的表示&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;time_t 从Epoch开始的秒数&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;calendar time 字符串&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;拆分时间 struct tm&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-C++&#34; data-lang=&#34;C++&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;struct&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tm&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; tm_sec;         &lt;span style=&#34;color:#75715e&#34;&gt;/* seconds */&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; tm_min;         &lt;span style=&#34;color:#75715e&#34;&gt;/* minutes */&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; tm_hour;        &lt;span style=&#34;color:#75715e&#34;&gt;/* hours */&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; tm_mday;        &lt;span style=&#34;color:#75715e&#34;&gt;/* day of the month */&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; tm_mon;         &lt;span style=&#34;color:#75715e&#34;&gt;/* month */&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; tm_year;        &lt;span style=&#34;color:#75715e&#34;&gt;/* year */&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; tm_wday;        &lt;span style=&#34;color:#75715e&#34;&gt;/* day of the week */&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; tm_yday;        &lt;span style=&#34;color:#75715e&#34;&gt;/* day in the year */&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; tm_isdst;       &lt;span style=&#34;color:#75715e&#34;&gt;/* daylight saving time */&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;};&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;struct timeval/struct timespec&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linux内核协议栈socket接口层</title>
      <link>https://feilengcui008.github.io/post/linux%E5%86%85%E6%A0%B8%E5%8D%8F%E8%AE%AE%E6%A0%88socket%E6%8E%A5%E5%8F%A3%E5%B1%82/</link>
      <pubDate>Sat, 31 Oct 2015 12:57:00 +0800</pubDate>
      <guid>https://feilengcui008.github.io/post/linux%E5%86%85%E6%A0%B8%E5%8D%8F%E8%AE%AE%E6%A0%88socket%E6%8E%A5%E5%8F%A3%E5%B1%82/</guid>
      <description>&lt;p&gt;本文接上一篇&lt;a href=&#34;http://blog.csdn.net/feilengcui008/article/details/49509993&#34;&gt;Linux内核协议栈-初始化流程分析&lt;/a&gt;，在上一篇中主要分析了了Linux内核协议栈涉及到的关键初始化函数，在这一篇文章中将分析协议栈的BSD socket和到传输层的流程。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;1.准备&#xA;协议的基本分层：&#xA;(A代表socket的某个系统调用)&#xA;BSD socket system calls A =&amp;gt; proto_ops-&amp;gt;A  =&amp;gt; sock-&amp;gt;A =&amp;gt; tcp_prot =&amp;gt; A&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;BSD socket层和具体协议族某个类型的联系是通过struct proto_ops，在include/linux/net.h中定义了不同协议族如af_inet，af_unix等的通用操作函数指针的结构体struct proto_ops，具体的定义有各个协议族的某个类型的子模块自己完成。比如ipv4/af_inet.c中定义的af_inet family的tcp/udp等相应的struct proto_ops。&lt;/li&gt;&#xA;&lt;li&gt;由于对于每个family的不同类型，其针对socket的某些需求可能不同，所以抽了一层struct sock出来，sock-&amp;gt;sk_prot挂接到具体tcp/udp等传输层的struct proto上(具体定义在ipv4/tcp_ipv4.c,ipv4/udp.c)&lt;/li&gt;&#xA;&lt;li&gt;另外，由于内容比较多，这一篇主要分析socket，bind，listen，accept几个系统调用，下一篇会涉及connect，send，recv等的分析&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;//不同协议族的通用函数hooks&#xA;//比如af_inet相关的定义在ipv4/af_inet.c中&#xA;//除了创建socket为系统调用外，基本针对socket层的操作函数都在这里面&#xA;struct proto_ops {&#xA;  int   family;&#xA;  struct module *owner;&#xA;  int   (*release)   (struct socket *sock);&#xA;  int   (*bind)      (struct socket *sock,&#xA;              struct sockaddr *myaddr,&#xA;              int sockaddr_len);&#xA;  int   (*connect)   (struct socket *sock,&#xA;              struct sockaddr *vaddr,&#xA;              int sockaddr_len, int flags);&#xA;  int   (*socketpair)(struct socket *sock1,&#xA;              struct socket *sock2);&#xA;  int   (*accept)    (struct socket *sock,&#xA;              struct socket *newsock, int flags);&#xA;  int   (*getname)   (struct socket *sock,&#xA;              struct sockaddr *addr,&#xA;              int *sockaddr_len, int peer);&#xA;  unsigned int  (*poll)      (struct file *file, struct socket *sock,&#xA;              struct poll_table_struct *wait);&#xA;  int   (*ioctl)     (struct socket *sock, unsigned int cmd,&#xA;              unsigned long arg);&#xA;#ifdef CONFIG_COMPAT&#xA;  int   (*compat_ioctl) (struct socket *sock, unsigned int cmd,&#xA;              unsigned long arg);&#xA;#endif&#xA;  int   (*listen)    (struct socket *sock, int len);&#xA;  int   (*shutdown)  (struct socket *sock, int flags);&#xA;  int   (*setsockopt)(struct socket *sock, int level,&#xA;              int optname, char __user *optval, unsigned int optlen);&#xA;/*省略部分*/&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;//传输层的proto &#xA;//作为sock-&amp;gt;sk_prot与具体传输层的hooks&#xA;struct proto {&#xA;  void      (*close)(struct sock *sk,&#xA;          long timeout);&#xA;  int     (*connect)(struct sock *sk,&#xA;          struct sockaddr *uaddr,&#xA;          int addr_len);&#xA;  int     (*disconnect)(struct sock *sk, int flags);&#xA;&#xA;  struct sock *   (*accept)(struct sock *sk, int flags, int *err);&#xA;&#xA;  int     (*ioctl)(struct sock *sk, int cmd,&#xA;           unsigned long arg);&#xA;  int     (*init)(struct sock *sk);&#xA;  void      (*destroy)(struct sock *sk);&#xA;  void      (*shutdown)(struct sock *sk, int how);&#xA;  int     (*setsockopt)(struct sock *sk, int level,&#xA;          int optname, char __user *optval,&#xA;          unsigned int optlen);&#xA;  int     (*getsockopt)(struct sock *sk, int level,&#xA;          int optname, char __user *optval,&#xA;          int __user *option);&#xA;#ifdef CONFIG_COMPAT&#xA;  int     (*compat_setsockopt)(struct sock *sk,&#xA;          int level,&#xA;          int optname, char __user *optval,&#xA;          unsigned int optlen);&#xA;  int     (*compat_getsockopt)(struct sock *sk,&#xA;          int level,&#xA;          int optname, char __user *optval,&#xA;          int __user *option);&#xA;  int     (*compat_ioctl)(struct sock *sk,&#xA;          unsigned int cmd, unsigned long arg);&#xA;#endif&#xA;  int     (*sendmsg)(struct kiocb *iocb, struct sock *sk,&#xA;             struct msghdr *msg, size_t len);&#xA;  int     (*recvmsg)(struct kiocb *iocb, struct sock *sk,&#xA;             struct msghdr *msg,&#xA;             size_t len, int noblock, int flags,&#xA;             int *addr_len);&#xA;  int     (*sendpage)(struct sock *sk, struct page *page,&#xA;          int offset, size_t size, int flags);&#xA;  int     (*bind)(struct sock *sk,&#xA;          struct sockaddr *uaddr, int addr_len);&#xA;&#xA;  /*省略部分*/&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;同时附上其他几个关键结构体：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linux内核协议栈初始化流程</title>
      <link>https://feilengcui008.github.io/post/linux%E5%86%85%E6%A0%B8%E5%8D%8F%E8%AE%AE%E6%A0%88%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Sat, 31 Oct 2015 10:35:43 +0800</pubDate>
      <guid>https://feilengcui008.github.io/post/linux%E5%86%85%E6%A0%B8%E5%8D%8F%E8%AE%AE%E6%A0%88%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B5%81%E7%A8%8B/</guid>
      <description>&lt;p&gt;本文主要针对Linux-3.19.3版本的内核简单分析内核协议栈初始化涉及到的关键步骤和主要函数。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;1.准备&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Linux内核协议栈本身构建在虚拟文件系统之上，所以对Linux VFS不太了解的可以参考内核源码根目录下Documentation/filesystems/vfs.txt，另外，socket接口层，协议层，设备层的许多数据结构涉及到内存管理，所以对基本虚拟内存管理，slab缓存，页高速缓存不太了解的也可以查阅相关文档。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;源码涉及的主要文件位于net/socket.c，net/core，include/linux/net*&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;2.开始&lt;/p&gt;&#xA;&lt;p&gt;开始分析前，这里有些小技巧可以快速定位到主要的初始化函数，在分析其他子系统源码时也可以采用这个技巧&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;grep _initcall socket.c&#xA;find ./core/ -name &amp;#34;*.c&amp;#34; |xargs cat | grep _initcall&#xA;grep net_inuse_init tags&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;http://img.blog.csdn.net/20151030132956270&#34; alt=&#34;这里写图片描述&#34;&gt;&#xA;&lt;img src=&#34;http://img.blog.csdn.net/20151030140301037&#34; alt=&#34;这里写图片描述&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这里*__initcall宏是设置初始化函数位于内核代码段.initcall#id.init的位置其中id代表优先级level，小的一般初始化靠前，定义在include/linux/init.h，使用gcc的attribute扩展。而各个level的初始化函数的调用流程基本如下：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;start_kernel -&amp;gt; rest_init -&amp;gt; kernel_init内核线程 -&amp;gt; kernel_init_freeable -&amp;gt; do_basic_setup -&amp;gt; do_initcalls -&amp;gt; do_initcall_level -&amp;gt; do_one_initcall -&amp;gt; *(initcall_t)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;http://img.blog.csdn.net/20151030133735173&#34; alt=&#34;这里写图片描述&#34;&gt;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;3.详细分析&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;可以看到pure_initcall(net_ns_init)位于0的初始化level，基本不依赖其他的初始化子系统，所以从这个开始&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;//core/net_namespace.c&#xA;//基本上这个函数主要的作用是初始化net结构init_net的一些数据，比如namespace相关，并且调用注册的pernet operations的init钩子针对net进行各自需求的初始化&#xA;pure_initcall(net_ns_init);&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;static int __init net_ns_init(void)&#xA;{&#xA;  struct net_generic *ng;&#xA;  //net namespace相关&#xA;#ifdef CONFIG_NET_NS&#xA;  //分配slab缓存&#xA;  net_cachep = kmem_cache_create(&amp;#34;net_namespace&amp;#34;, sizeof(struct net),SMP_CACHE_BYTES,SLAB_PANIC, NULL);&#xA;&#xA;  /* Create workqueue for cleanup */&#xA;  netns_wq = create_singlethread_workqueue(&amp;#34;netns&amp;#34;);&#xA;  if (!netns_wq)&#xA;    panic(&amp;#34;Could not create netns workq&amp;#34;);&#xA;#endif&#xA;  ng = net_alloc_generic();&#xA;  if (!ng)&#xA;    panic(&amp;#34;Could not allocate generic netns&amp;#34;);&#xA;&#xA;  rcu_assign_pointer(init_net.gen, ng);&#xA;  mutex_lock(&amp;amp;net_mutex);&#xA;    //初始化net namespace相关的对象, 传入初始的namespace init_user_ns&#xA;    //设置net结构的初始namespace&#xA;    //对每个pernet_list中注册的pernet operation，调用其初始化net中的对应数据对象&#xA;  if (setup_net(&amp;amp;init_net, &amp;amp;init_user_ns))&#xA;    panic(&amp;#34;Could not setup the initial network namespace&amp;#34;);&#xA;&#xA;  rtnl_lock();&#xA;    //加入初始net结构的list中&#xA;  list_add_tail_rcu(&amp;amp;init_net.list, &amp;amp;net_namespace_list);&#xA;  rtnl_unlock();&#xA;  mutex_unlock(&amp;amp;net_mutex);&#xA;    //加入pernet_list链表，并且调用pernet operation的init函数初始化net &#xA;  register_pernet_subsys(&amp;amp;net_ns_ops);&#xA;  return 0;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;下面分析core_init(sock_init)：&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;//socket.c&#xA;//在.initcall1.init代码段注册，以便内核启动时do_initcalls中调用&#xA;//从而注册socket filesystem &#xA;core_initcall(sock_init); /* early initcall */&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;进入core_init(sock_init):&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linux内核页高速缓存</title>
      <link>https://feilengcui008.github.io/post/linux%E5%86%85%E6%A0%B8%E9%A1%B5%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98/</link>
      <pubDate>Tue, 20 Oct 2015 18:51:24 +0800</pubDate>
      <guid>https://feilengcui008.github.io/post/linux%E5%86%85%E6%A0%B8%E9%A1%B5%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98/</guid>
      <description>&lt;p&gt;Linux内核的VFS是非常经典的抽象，不仅抽象出了flesystem，super_block，inode，dentry，file等结构，而且还提供了像页高速缓存层的通用接口，当然，你可以自己选择是否使用或者自己定制使用方式。本文主要根据自己阅读Linux Kernel 3.19.3系统调用read相关的源码来追踪页高速缓存在整个流程中的痕迹，以常规文件的页高速缓存为例，了解页高速缓存的实现过程，不过于追究具体bio请求的底层细节。另外，在写操作的过程中，页高速缓存的处理流程有所不同(回写)，涉及的东西更多，本文主要关注读操作。Linux VFS相关的重要数据结构及概念可以参考Document目录下的&lt;a href=&#34;https://www.kernel.org/doc/Documentation/filesystems/vfs.txt&#34;&gt;vfs.txt&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h4 id=&#34;1与页高速缓存相关的重要数据结构&#34;&gt;1.与页高速缓存相关的重要数据结构&lt;/h4&gt;&#xA;&lt;p&gt;除了前述基本数据结构以外，struct address_space 和 struct address_space_operations也在页高速缓存中起着极其重要的作用。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;address_space结构通常被struct page的一个字段指向，主要存放已缓存页面的相关信息，便于快速查找对应文件的缓存页面，具体查找过程是通过radix tree结构的相关操作实现的。&lt;/li&gt;&#xA;&lt;li&gt;address_space_operations结构定义了具体读写页面等操作的钩子，比如生成并发送bio请求，我们可以定制相应的函数实现自己的读写逻辑。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;//include/linux/fs.h&#xA;struct address_space {&#xA;    //指向文件的inode，可能为NULL&#xA;  struct inode    *host;  &#xA;  //存放装有缓存数据的页面&#xA;  struct radix_tree_root  page_tree;  &#xA;  spinlock_t    tree_lock;  &#xA;  atomic_t    i_mmap_writable;&#xA;  struct rb_root    i_mmap; &#xA;  struct list_head  i_mmap_nonlinear;&#xA;  struct rw_semaphore i_mmap_rwsem;&#xA;  //已缓存页的数量&#xA;  unsigned long   nrpages;  &#xA;  unsigned long   nrshadows;  &#xA;  pgoff_t     writeback_index;&#xA;  //address_space相关操作，定义了具体读写页面的钩子&#xA;  const struct address_space_operations *a_ops; &#xA;  unsigned long   flags;  &#xA;  struct backing_dev_info *backing_dev_info; &#xA;  spinlock_t    private_lock; &#xA;  struct list_head  private_list; &#xA;  void      *private_data;&#xA;} __attribute__((aligned(sizeof(long))));&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;//include/linux/fs.h &#xA;struct address_space_operations {&#xA;    //具体写页面的操作&#xA;  int (*writepage)(struct page *page, struct writeback_control *wbc);&#xA;  //具体读页面的操作&#xA;  int (*readpage)(struct file *, struct page *);&#xA;  int (*writepages)(struct address_space *, struct writeback_control *);&#xA;    //标记页面脏&#xA;  int (*set_page_dirty)(struct page *page);&#xA;  int (*readpages)(struct file *filp, struct address_space *mapping, struct list_head *pages, unsigned nr_pages);&#xA;  int (*write_begin)(struct file *, struct address_space  *mapping, loff_t pos, unsigned len, unsigned flags, struct page **pagep, void **fsdata);&#xA;  int (*write_end)(struct file *, struct address_space *mapping, loff_t pos, unsigned len, unsigned copied, struct page *page, void *fsdata);&#xA;  sector_t (*bmap)(struct address_space *, sector_t);&#xA;  void (*invalidatepage) (struct page *, unsigned int, unsigned int);&#xA;  int (*releasepage) (struct page *, gfp_t);&#xA;  void (*freepage)(struct page *);&#xA;  ssize_t (*direct_IO)(int, struct kiocb *, struct iov_iter *iter, loff_t offset);&#xA;  int (*get_xip_mem)(struct address_space *, pgoff_t, int, void **, unsigned long *);&#xA;&#xA;  int (*migratepage) (struct address_space *, struct page *, struct page *, enum migrate_mode);&#xA;  int (*launder_page) (struct page *);&#xA;  int (*is_partially_uptodate) (struct page *, unsigned long, unsigned long);&#xA;  void (*is_dirty_writeback) (struct page *, bool *, bool *);&#xA;  int (*error_remove_page)(struct address_space *, struct page *);&#xA;  /* swapfile support */&#xA;  int (*swap_activate)(struct swap_info_struct *sis, struct file *file, sector_t *span);&#xA;  void (*swap_deactivate)(struct file *file);&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;&#xA;&lt;h4 id=&#34;2系统调用read流程与页高速缓存相关代码分析&#34;&gt;2.系统调用read流程与页高速缓存相关代码分析&lt;/h4&gt;&#xA;&lt;p&gt;关于挂载和打开文件的操作，不赘述(涉及的细节也很多&amp;hellip;)，(极其)简陋地理解，挂载返回挂载点的root dentry，并且读取磁盘数据生成了super_block链接到全局超级块链表中，这样，当前进程就可以通过root dentry找到其inode，从而找到并生成其子树的dentry和inode信息，从而实现查找路径的逻辑。打开文件简单理解就是分配fd，通过dentry将file结构与对应inode挂接，最后安装到进程的打开文件数组中，这里假设已经成功打开文件，返回了fd，我们从系统调用read开始。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linux内核内存访问与缺页中断</title>
      <link>https://feilengcui008.github.io/post/linux%E5%86%85%E6%A0%B8%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E4%B8%8E%E7%BC%BA%E9%A1%B5%E4%B8%AD%E6%96%AD/</link>
      <pubDate>Fri, 16 Oct 2015 18:12:15 +0800</pubDate>
      <guid>https://feilengcui008.github.io/post/linux%E5%86%85%E6%A0%B8%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E4%B8%8E%E7%BC%BA%E9%A1%B5%E4%B8%AD%E6%96%AD/</guid>
      <description>&lt;p&gt;简单描述了x86 32位体系结构下Linux内核的用户进程和内核线程的线性地址空间和物理内存的联系，分析了高端内存的引入与缺页中断的具体处理流程。先介绍了用户态进程的执行流程，然后对比了内核线程，引入高端内存的概念，最后分析了缺页中断的流程。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;用户进程&#xA;fork之后的用户态进程已经建立好了所需的数据结构，比如task struct，thread info，mm struct等，将编译链接好的可执行程序的地址区域与进程结构中内存区域做好映射，等开始执行的时候，访问并未经过映射的用户地址空间，会发生缺页中断，然后内核态的对应中断处理程序负责分配page，并将用户进程空间导致缺页的地址与page关联，然后检查是否有相同程序文件的buffer，因为可能其他进程执行同一个程序文件，已经将程序读到buffer里边了，如果没有，则将磁盘上的程序部分读到buffer，而buffer head通常是与分配的页面相关联的，所以实际上会读到对应页面代表的物理内存之中，返回到用户态导致缺页的地址继续执行，此时经过mmu的翻译，用户态地址成功映射到对应页面和物理地址，然后读取指令执行。在上述过程中，如果由于内存耗尽或者权限的问题，可能会返回-NOMEM或segment fault错误给用户态进程。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;内核线程&#xA;没有独立的mm结构，所有内核线程共享一个内核地址空间与内核页表，由于为了方便系统调用等，在用户态进程规定了内核的地址空间是高1G的线性地址，而低3G线性地址空间供用户态使用。注意这部分是和用户态进程的线性地址是重合的，经过mmu的翻译，会转换到相同的物理地址，即前1G的物理地址（准确来讲后128M某些部分的物理地址可能会变化），内核线程访问内存也是要经过mmu的，所以借助用户态进程的页表，虽然内核有自己的内核页表，但不直接使用（为了减少用户态和内核态页表切换的消耗？），用户进程页表的高1G部分实际上是共享内核页表的映射的，访问高1G的线性地址时能访问到低1G的物理地址。而且，由于从用户进程角度看，内核地址空间只有3G－4G这一段（内核是无法直接访问0－3G的线性地址空间的，因为这一段是用户进程所有，一方面如果内核直接读写0－3G的线性地址可能会毁坏进程数据结构，另一方面，不同用户态进程线性地址空间实际映射到不同的物理内存地址，所以可能此刻内核线程借助这个用户态进程的页表成功映射到某个物理地址，但是到下一刻，借助下一个用户态进程的页表，相同的线性地址就可能映射到不同的物理内存地址了）。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;高端内存&#xA;那么，如何让内核访问到大于1G的物理内存？由此引入高端内存的概念，基本思路就是将3G－4G这1G的内核线性地址空间（从用户进程的角度看，从内核线程的角度看是0－1G）取出一部分挪作他用，而不是固定映射，即重用部分内核线性地址空间，映射到1G之上的物理内存。所以，对于x86 32位体系上的Linux内核将3G－4G的线性地址空间分为0－896m和896m－1G的部分，前面部分使用固定映射，当内核使用进程页表访问3G－3G＋896m的线性地址时，不会发生缺页中断，但是当访问3G＋896m以上的线性地址时，可能由于内核页表被更新，而进程页表还未和内核页表同步，此时会发生内核地址空间的缺页中断，从而将内核页表同步到当前进程页表。注意，使用vmalloc分配内存的时候，可能已经设置好了内核页表，等到下一次借助进程页表访问内核空间地址发生缺页时才会触发内核页表和当前页表的同步。&#xA;Linux x86 32位下的线性地址空间与物理地址空间&#xA;(图片出自《understanding the linux virtual memory manager》)&#xA;&lt;img src=&#34;http://img.blog.csdn.net/20151016181439699&#34; alt=&#34;这里写图片描述&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;缺页&#xA;page fault的处理过程如下：在用户空间上下文和内核上下文下都可能访问缺页的线性地址导致缺页中断，但有些情况没有实际意义。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果缺页地址位于内核线性地址空间&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果在vmalloc区，则同步内核页表和用户进程页表，否则挂掉。注意此处未分具体上下文&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;如果发生在中断上下文或者!mm，则检查exception table，如果没有则挂掉。&lt;/li&gt;&#xA;&lt;li&gt;如果缺页地址发生在用户进程线性地址空间&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果在内核上下文，则查exception table，如果没有，则挂掉。这种情况没多大实际意义&lt;/li&gt;&#xA;&lt;li&gt;如果在用户进程上下文&#xA;&lt;ul&gt;&#xA;&lt;li&gt;查找vma，找到，先判断是否需要栈扩张，否则进入通常的处理流程&lt;/li&gt;&#xA;&lt;li&gt;查找vma，未找到，bad area，通常返回segment fault&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;具体的缺页中断流程图及代码如下：&#xA;(图片出自《understanding the linux virtual memory manager》)&#xA;&lt;img src=&#34;http://img.blog.csdn.net/20151016181719231&#34; alt=&#34;这里写图片描述&#34;&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;（Linux 3.19.3 arch/x86/mm/fault.c 1044）&#xA;/*&#xA; * This routine handles page faults.  It determines the address,&#xA; * and the problem, and then passes it off to one of the appropriate&#xA; * routines.&#xA; *&#xA; * This function must have noinline because both callers&#xA; * {,trace_}do_page_fault() have notrace on. Having this an actual function&#xA; * guarantees there&amp;#39;s a function trace entry.&#xA; */&#xA;&#xA;//处理缺页中断&#xA;//参数：寄存器值，错误码，缺页地址&#xA;static noinline void&#xA;__do_page_fault(struct pt_regs *regs, unsigned long error_code,&#xA;    unsigned long address)&#xA;{&#xA;  struct vm_area_struct *vma;&#xA;  struct task_struct *tsk;&#xA;  struct mm_struct *mm;&#xA;  int fault, major = 0;&#xA;  unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;&#xA;&#xA;  tsk = current;&#xA;  mm = tsk-&amp;gt;mm;&#xA;&#xA;  /*&#xA;   * Detect and handle instructions that would cause a page fault for&#xA;   * both a tracked kernel page and a userspace page.&#xA;   */&#xA;  if (kmemcheck_active(regs))&#xA;    kmemcheck_hide(regs);&#xA;  prefetchw(&amp;amp;mm-&amp;gt;mmap_sem);&#xA;&#xA;  if (unlikely(kmmio_fault(regs, address)))&#xA;    return;&#xA;&#xA;  /*&#xA;   * We fault-in kernel-space virtual memory on-demand. The&#xA;   * &amp;#39;reference&amp;#39; page table is init_mm.pgd.&#xA;   *&#xA;   * NOTE! We MUST NOT take any locks for this case. We may&#xA;   * be in an interrupt or a critical region, and should&#xA;   * only copy the information from the master page table,&#xA;   * nothing more.&#xA;   *&#xA;   * This verifies that the fault happens in kernel space&#xA;   * (error_code &amp;amp; 4) == 0, and that the fault was not a&#xA;   * protection error (error_code &amp;amp; 9) == 0.&#xA;   */&#xA;&#xA;    //如果缺页地址位于内核空间&#xA;  if (unlikely(fault_in_kernel_space(address))) {&#xA;    if (!(error_code &amp;amp; (PF_RSVD | PF_USER | PF_PROT))) { //位于内核上下文&#xA;      if (vmalloc_fault(address) &amp;gt;= 0) //如果位于vmalloc区域 vmalloc_sync_one同步内核页表进程页表 &#xA;        return;&#xA;&#xA;      if (kmemcheck_fault(regs, address, error_code))&#xA;        return;&#xA;    }&#xA;&#xA;    /* Can handle a stale RO-&amp;gt;RW TLB: */&#xA;    if (spurious_fault(error_code, address))&#xA;      return;&#xA;&#xA;    /* kprobes don&amp;#39;t want to hook the spurious faults: */&#xA;    if (kprobes_fault(regs))&#xA;      return;&#xA;    /*&#xA;     * Don&amp;#39;t take the mm semaphore here. If we fixup a prefetch&#xA;     * fault we could otherwise deadlock:&#xA;     */&#xA;    bad_area_nosemaphore(regs, error_code, address);&#xA;&#xA;    return;&#xA;  }&#xA;&#xA;&#xA;&#xA;  /* kprobes don&amp;#39;t want to hook the spurious faults: */&#xA;  if (unlikely(kprobes_fault(regs)))&#xA;    return;&#xA;&#xA;  if (unlikely(error_code &amp;amp; PF_RSVD))&#xA;    pgtable_bad(regs, error_code, address);&#xA;&#xA;  if (unlikely(smap_violation(error_code, regs))) {&#xA;    bad_area_nosemaphore(regs, error_code, address);&#xA;    return;&#xA;  }&#xA;&#xA;  /*&#xA;   * If we&amp;#39;re in an interrupt, have no user context or are running&#xA;   * in an atomic region then we must not take the fault:&#xA;   */&#xA;&#xA;    //如果位于中断上下文或者!mm, 出错&#xA;  if (unlikely(in_atomic() || !mm)) {&#xA;    bad_area_nosemaphore(regs, error_code, address);&#xA;    return;&#xA;  }&#xA;&#xA;  /*&#xA;   * It&amp;#39;s safe to allow irq&amp;#39;s after cr2 has been saved and the&#xA;   * vmalloc fault has been handled.&#xA;   *&#xA;   * User-mode registers count as a user access even for any&#xA;   * potential system fault or CPU buglet:&#xA;   */&#xA;  if (user_mode_vm(regs)) {&#xA;    local_irq_enable();&#xA;    error_code |= PF_USER;&#xA;    flags |= FAULT_FLAG_USER;&#xA;  } else {&#xA;    if (regs-&amp;gt;flags &amp;amp; X86_EFLAGS_IF)&#xA;      local_irq_enable();&#xA;  }&#xA;&#xA;  perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, address);&#xA;&#xA;  if (error_code &amp;amp; PF_WRITE)&#xA;    flags |= FAULT_FLAG_WRITE;&#xA;&#xA;  /*&#xA;   * When running in the kernel we expect faults to occur only to&#xA;   * addresses in user space.  All other faults represent errors in&#xA;   * the kernel and should generate an OOPS.  Unfortunately, in the&#xA;   * case of an erroneous fault occurring in a code path which already&#xA;   * holds mmap_sem we will deadlock attempting to validate the fault&#xA;   * against the address space.  Luckily the kernel only validly&#xA;   * references user space from well defined areas of code, which are&#xA;   * listed in the exceptions table.&#xA;   *&#xA;   * As the vast majority of faults will be valid we will only perform&#xA;   * the source reference check when there is a possibility of a&#xA;   * deadlock. Attempt to lock the address space, if we cannot we then&#xA;   * validate the source. If this is invalid we can skip the address&#xA;   * space check, thus avoiding the deadlock:&#xA;   */&#xA;  if (unlikely(!down_read_trylock(&amp;amp;mm-&amp;gt;mmap_sem))) {&#xA;    if ((error_code &amp;amp; PF_USER) == 0 &amp;amp;&amp;amp;&#xA;        !search_exception_tables(regs-&amp;gt;ip)) {&#xA;      bad_area_nosemaphore(regs, error_code, address);&#xA;      return;&#xA;    }&#xA;retry:&#xA;    down_read(&amp;amp;mm-&amp;gt;mmap_sem);&#xA;  } else {&#xA;    /*&#xA;     * The above down_read_trylock() might have succeeded in&#xA;     * which case we&amp;#39;ll have missed the might_sleep() from&#xA;     * down_read():&#xA;     */&#xA;    might_sleep();&#xA;  }&#xA;&#xA;&#xA;    //缺页中断地址位于用户空间 &#xA;    //查找vma &#xA;  vma = find_vma(mm, address);&#xA;&#xA;    //没找到，出错&#xA;  if (unlikely(!vma)) {&#xA;    bad_area(regs, error_code, address);&#xA;    return;&#xA;  }&#xA;&#xA;    //检查在vma的地址的合法性&#xA;  if (likely(vma-&amp;gt;vm_start &amp;lt;= address))&#xA;    goto good_area;&#xA;&#xA;  if (unlikely(!(vma-&amp;gt;vm_flags &amp;amp; VM_GROWSDOWN))) {&#xA;    bad_area(regs, error_code, address);&#xA;    return;&#xA;  }&#xA;&#xA;    //如果在用户上下文&#xA;  if (error_code &amp;amp; PF_USER) {&#xA;    /*&#xA;     * Accessing the stack below %sp is always a bug.&#xA;     * The large cushion allows instructions like enter&#xA;     * and pusha to work. (&amp;#34;enter $65535, $31&amp;#34; pushes&#xA;     * 32 pointers and then decrements %sp by 65535.)&#xA;     */&#xA;    if (unlikely(address + 65536 + 32 * sizeof(unsigned long) &amp;lt; regs-&amp;gt;sp)) {&#xA;      bad_area(regs, error_code, address);&#xA;      return;&#xA;    }&#xA;  }&#xA;&#xA;    //栈扩张&#xA;  if (unlikely(expand_stack(vma, address))) {&#xA;    bad_area(regs, error_code, address);&#xA;    return;&#xA;  }&#xA;&#xA;  /*&#xA;   * Ok, we have a good vm_area for this memory access, so&#xA;   * we can handle it..&#xA;   */&#xA;&#xA;    //vma合法 &#xA;good_area:&#xA;  if (unlikely(access_error(error_code, vma))) {&#xA;    bad_area_access_error(regs, error_code, address);&#xA;    return;&#xA;  }&#xA;&#xA;  /*&#xA;   * If for any reason at all we couldn&amp;#39;t handle the fault,&#xA;   * make sure we exit gracefully rather than endlessly redo&#xA;   * the fault.  Since we never set FAULT_FLAG_RETRY_NOWAIT, if&#xA;   * we get VM_FAULT_RETRY back, the mmap_sem has been unlocked.&#xA;   */&#xA;&#xA;    //调用通用的缺页处理&#xA;  fault = handle_mm_fault(mm, vma, address, flags);&#xA;  major |= fault &amp;amp; VM_FAULT_MAJOR;&#xA;&#xA;  /*&#xA;   * If we need to retry the mmap_sem has already been released,&#xA;   * and if there is a fatal signal pending there is no guarantee&#xA;   * that we made any progress. Handle this case first.&#xA;   */&#xA;  if (unlikely(fault &amp;amp; VM_FAULT_RETRY)) {&#xA;    /* Retry at most once */&#xA;    if (flags &amp;amp; FAULT_FLAG_ALLOW_RETRY) {&#xA;      flags &amp;amp;= ~FAULT_FLAG_ALLOW_RETRY;&#xA;      flags |= FAULT_FLAG_TRIED;&#xA;      if (!fatal_signal_pending(tsk))&#xA;        goto retry;&#xA;    }&#xA;&#xA;    /* User mode? Just return to handle the fatal exception */&#xA;    if (flags &amp;amp; FAULT_FLAG_USER)&#xA;      return;&#xA;&#xA;    /* Not returning to user mode? Handle exceptions or die: */&#xA;    no_context(regs, error_code, address, SIGBUS, BUS_ADRERR);&#xA;    return;&#xA;  }&#xA;&#xA;  up_read(&amp;amp;mm-&amp;gt;mmap_sem);&#xA;  if (unlikely(fault &amp;amp; VM_FAULT_ERROR)) {&#xA;    mm_fault_error(regs, error_code, address, fault);&#xA;    return;&#xA;  }&#xA;&#xA;  /*&#xA;   * Major/minor page fault accounting. If any of the events&#xA;   * returned VM_FAULT_MAJOR, we account it as a major fault.&#xA;   */&#xA;  if (major) {&#xA;    tsk-&amp;gt;maj_flt++;&#xA;    perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1, regs, address);&#xA;  } else {&#xA;    tsk-&amp;gt;min_flt++;&#xA;    perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1, regs, address);&#xA;  }&#xA;&#xA;  check_v8086_mode(regs, address, tsk);&#xA;}&#xA;NOKPROBE_SYMBOL(__do_page_fault);&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>Linux内核编译与启动流程</title>
      <link>https://feilengcui008.github.io/post/linux%E5%86%85%E6%A0%B8%E7%BC%96%E8%AF%91%E4%B8%8E%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/</link>
      <pubDate>Sun, 20 Sep 2015 23:27:03 +0800</pubDate>
      <guid>https://feilengcui008.github.io/post/linux%E5%86%85%E6%A0%B8%E7%BC%96%E8%AF%91%E4%B8%8E%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/</guid>
      <description>&lt;h3 id=&#34;编译流程&#34;&gt;编译流程&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;1.编译除arch/x86/boot目录外的其他目录，生成各模块的built_in.o，将静态编译进内核的模块链接成ELF格式的文件vmlinux大约100M，置于源码根目录之下&lt;/li&gt;&#xA;&lt;li&gt;2.通过objcopy将源码根目录下的vmlinux去掉符号等信息置于arch/x86/boot/compressed/vmlinux.bin，大约15M，将其压缩为boot/vmlinux.bin.gz(假设配置的压缩工具是gzip)。&lt;/li&gt;&#xA;&lt;li&gt;3.使用生成的compressed/mkpiggy为compressed/vmlinux.bin.gz添加解压缩程序头，生成compressed/piggy.S，进而生成compressed/piggy.o。&lt;/li&gt;&#xA;&lt;li&gt;4.将compressed/head_64.o，compressed/misc.o，compressed/piggy.o链接为compressed/vmlinux。&lt;/li&gt;&#xA;&lt;li&gt;5.回到boot目录，用objcopy为compressed/vmlinux去掉符号等信息生成boot/vmlinux.bin。&lt;/li&gt;&#xA;&lt;li&gt;6.将boot/setup.bin与boot/vmlinux.bin链接，生成bzImage。&lt;/li&gt;&#xA;&lt;li&gt;7.将各个设置为动态编译的模块链接为内核模块kmo。&lt;/li&gt;&#xA;&lt;li&gt;8.over，maybe copy bzImage to /boot and kmods to /lib.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;下面是内核镜像的组成:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://img.blog.csdn.net/20150920225335155&#34; alt=&#34;这里写图片描述&#34;&gt;&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;启动流程&#34;&gt;启动流程&lt;/h3&gt;&#xA;&lt;p&gt;早期版本的linux内核，如0.1，是通过自带的bootsect.S/setup.S引导，现在需要通过bootloader如grub/lilo来引导。grub的作用大致如下:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;1.grub安装时将stage1 512字节和所在分区文件系统类型对应的stage1.5文件分别写入mbr和之后的扇区。&lt;/li&gt;&#xA;&lt;li&gt;2.bios通过中断加载mbr的512个字节的扇区到0x7c00地址，跳转到0x07c0:0x0000执行。&lt;/li&gt;&#xA;&lt;li&gt;3.通过bios中断加载/boot/grub下的stage2，读取/boot/grub/menu.lst配置文件生成启动引导菜单。&lt;/li&gt;&#xA;&lt;li&gt;4.加载/boot/vmlinuz-xxx-xx与/boot/inird-xxx，将控制权交给内核。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;下面是较为详细的步骤:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;1.BIOS加载硬盘第一个扇区(MBR 512字节)到0000:07C00处，MBR包含引导代码(446字节，比如grub第一阶段的引导代码)，分区表(64字节)信息，结束标志0xAA55(2字节)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;2.MBR开始执行加载活跃分区，grub第一阶段代码加载1.5阶段的文件系统相关的代码(通过bios中断读活跃分区的扇区)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;3.有了grub1.5阶段的文件系统相关的模块，接下来读取位于文件系统的grub第2阶段的代码，并执行&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;4.grub第2阶段的代码读取/boot/grub.cfg文件，生成引导菜单&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;5.加载对应的压缩内核vmlinuz和initrd（到哪个地址？）&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;6.实模式下执行vmlinuz头setup部分(bootsect和setup)[head.S[calll main],main.c[go_to_protected_mode]]  ==&amp;gt; 准备进入32位保护模式&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;7.跳转到过渡的32位保护模式执行compressed/head_64.S[startup_32,startup_64]  ==&amp;gt; 进入临时的32位保护模式&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;8.解压缩剩余的vmlinuz，设置页表等，设置64位环境，跳转到解压地址执行  ==&amp;gt; 进入64位&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;9.arch/x86/kernel/head_64.S[startup_64]&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;10.arch/x86/kernel/head64.c[x86_64_start_up]&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;11.init/main.c[start_kernel]&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;12.然后后面的事情就比较好知道了:)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;ref: Linux source code 3.19.3&lt;/p&gt;&#xA;&lt;/blockquote&gt;</description>
    </item>
    <item>
      <title>Linux下x86_64进程地址空间布局</title>
      <link>https://feilengcui008.github.io/post/linux%E4%B8%8Bx86_64%E8%BF%9B%E7%A8%8B%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%E5%B8%83%E5%B1%80/</link>
      <pubDate>Sun, 08 Mar 2015 23:33:03 +0800</pubDate>
      <guid>https://feilengcui008.github.io/post/linux%E4%B8%8Bx86_64%E8%BF%9B%E7%A8%8B%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%E5%B8%83%E5%B1%80/</guid>
      <description>&lt;p&gt;关于Linux 32位内存下的内存空间布局，可以参考这篇博文&lt;a href=&#34;http://blog.csdn.net/embedded_hunter/article/details/6897027&#34;&gt;Linux下C程序进程地址空间局&lt;/a&gt;关于源代码中各种数据类型/代码在elf格式文件以及进程空间中所处的段，在x86_64下和i386下是类似的，本文主要关注vm.legacy_va_layout以及kernel.randomize_va_space参数影响下的进程空间内存宏观布局，以及vDSO和多线程下的堆和栈分布。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;情形一&#34;&gt;情形一：&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;vm_legacy_va_layout=1&lt;/li&gt;&#xA;&lt;li&gt;kernel.randomize_va_space=0&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;此种情况下采用传统内存布局方式，不开启随机化，程序的内存布局&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://img.blog.csdn.net/20150308225850362&#34; alt=&#34;&#34;&gt;&#xA;可以看出:&#xA;代码段：0x400000&amp;ndash;&amp;gt;&#xA;数据段&#xA;堆：向上增长 2aaaaaaab000&amp;ndash;&amp;gt;&#xA;栈：7ffffffde000&amp;lt;&amp;ndash;7ffffffff000&#xA;系统调用：ffffffffff600000-ffffffffff601000&#xA;你可以试一下其他程序，在kernel.randomize_va_space=0时堆起点是不变的&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;情形二&#34;&gt;情形二：&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;vm_legacy_va_layout=0&lt;/li&gt;&#xA;&lt;li&gt;kernel.randomize_va_space=0&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;现在默认内存布局，不随机化&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://img.blog.csdn.net/20150308231829505&#34; alt=&#34;&#34;&gt;&#xA;可以看出:&#xA;代码段：0x400000&amp;ndash;&amp;gt;&#xA;数据段&#xA;堆：向下增长 &amp;lt;&amp;ndash;7ffff7fff000&#xA;栈：7ffffffde000&amp;lt;&amp;ndash;7ffffffff000&#xA;系统调用：ffffffffff600000-ffffffffff601000&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;情形三&#34;&gt;情形三：&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;vm_legacy_va_layout=0&lt;/li&gt;&#xA;&lt;li&gt;kernel.randomize_va_space=2 //ubuntu 14.04默认值&#xA;使用现在默认布局，随机化&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://img.blog.csdn.net/20150308232612405&#34; alt=&#34;&#34;&gt;&#xA;&lt;img src=&#34;http://img.blog.csdn.net/20150308232738454&#34; alt=&#34;&#34;&gt;&#xA;对比两次启动的cat程序，其内存布局堆的起点是变化的，这从一定程度上防止了缓冲区溢出攻击。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;情形四&#34;&gt;情形四：&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;vm_legacy_va_layout=1&lt;/li&gt;&#xA;&lt;li&gt;kernel.randomize_va_space=2 //ubuntu 14.04默认值&#xA;与情形三类似，不再赘述&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;vdso&#34;&gt;vDSO&lt;/h3&gt;&#xA;&lt;p&gt;在前面谈了两个不同参数下的进程运行时内存空间宏观的分布。也许你会注意到这样一个细节，在每个进程的stack以上的地址中，有一段动态变化的映射地址段，比如下面这个进程，映射到vdso。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://img.blog.csdn.net/20150314205520905&#34; alt=&#34;cat&#34;&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;如果我们用ldd看相应的程序，会发现vdso在磁盘上没有对应的so文件。&#xA;不记得曾经在哪里看到大概这样一个问题：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;getpid，gettimeofday是不是系统调用？&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;其实这个问题的答案就和vDSO有关，杂x86_64和i386上，getpid是系统调用，而gettimeofday不是。&lt;/p&gt;&#xA;&lt;p&gt;vDSO全称是virtual dynamic shared object，是一种内核将一些本身应该是系统调用的直接映射到用户空间，这样对于一些使用比较频繁的系统调用，直接在用户空间调用可以节省开销。如果想详细了解，可以参考&lt;a href=&#34;http://man7.org/linux/man-pages/man7/vdso.7.html&#34;&gt;这篇文档&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;下面我们用一段程序验证下：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#include &amp;lt;stdio.h&amp;gt;&#xA;#include &amp;lt;sys/time.h&amp;gt;&#xA;#include &amp;lt;sys/syscall.h&amp;gt;&#xA;#include &amp;lt;unistd.h&amp;gt;&#xA;&#xA;int main(int argc, char **argv)&#xA;{&#xA;    struct timeval tv;&#xA;    int ret;&#xA;    if ((ret=gettimeofday(&amp;amp;tv, NULL))&amp;lt;0) {&#xA;        fprintf(stderr, &amp;#34;gettimeofday call failed\n&amp;#34;);&#xA;    }else{&#xA;        fprintf(stdout, &amp;#34;seconds:%ld\n&amp;#34;, (long int)tv.tv_sec);&#xA;    }&#xA;&#xA;    fprintf(stdout, &amp;#34;pid:%d\n&amp;#34;, (int)getpid());&#xA;    fprintf(stdout, &amp;#34;thread id:%d\n&amp;#34;, (int)syscall(SYS_gettid));&#xA;    return 0;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;编译为可执行文件后，我们可以用strace来验证：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linux网络编程小结</title>
      <link>https://feilengcui008.github.io/post/linux%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%B0%8F%E7%BB%93/</link>
      <pubDate>Wed, 04 Mar 2015 22:37:15 +0800</pubDate>
      <guid>https://feilengcui008.github.io/post/linux%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%B0%8F%E7%BB%93/</guid>
      <description>&lt;p&gt;网络编程是一个很大也很有趣的话题，要写好一个高性能并且bug少的服务端或者客户端程序还是挺不容易的，而且往往涉及到进程线程管理、内存管理、协议栈、并发等许多相关的知识，而不仅仅只是会使用socket那么简单。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;网络编程模型&#34;&gt;网络编程模型&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;阻塞和非阻塞&#xA;阻塞和非阻塞通常是指文件描述符本身的属性。对于默认阻塞的socket来说，当socket读缓冲区中没有数据或者写缓冲区满时，都会造成read/recv或者write/send系统调用阻塞，而非阻塞socket在这种情况下会产生EWOULDBLOCK或者EAGAIN等错误并立即返回，不会等待socket变得可读或者可写。在Linux下我们可以通过accept4/fcntl系统调用设置socket为非阻塞。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;同步/异步&#xA;同步和异步可以分两层理解。一个是底层OS提供的IO基础设施的同步和异步，另一个是编程方式上的同步和异步。同步IO和异步IO更多地是怎么处理读写问题的一种手段。通常这也对应着两种高性能网络编程模式reactor和proactor。同步通常是事件发生时主动读写数据，直到显示地返回读写状态标志；而异步通常是我们交给操作系统帮我们读写，只需要注册读写完成的回调函数，提交读写的请求后，控制权就返回到进程。对于编程方式上的异步，典型的比如事件循环的回调、C++11的std::async/std::future等等，更多的是通过回调或者线程的方式组织异步的代码逻辑。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;IO复用&#xA;IO复用通常是用select/poll/epoll等来统一代理多个socket的事件的发生。select是一种比较通用的多路复用技术，poll是Linux平台下对select做的改进，而epoll是目前Linux下最常用的多路复用技术。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;常见网络库采用的模型只看epoll&#34;&gt;常见网络库采用的模型(只看epoll)：&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;nginx：master进程+多个worker进程，one eventloop per process&lt;/li&gt;&#xA;&lt;li&gt;memcached：主线程+多个worker线程，one eventloop per thread&lt;/li&gt;&#xA;&lt;li&gt;tornado：单线程，one eventloop per thread&lt;/li&gt;&#xA;&lt;li&gt;muduo：网络库，one eventloop per thread&lt;/li&gt;&#xA;&lt;li&gt;libevent、libev、boost.asio：网络库，跨平台eventloop封装&lt;/li&gt;&#xA;&lt;li&gt;&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;排除掉传统的单线程、多进程、多线程等模型，最常用的高性能网络编程模型是one eventloop per thread与多线程的组合。另外，为了处理耗时的任务再加上线程池，为了更好的内存管理再加上对象池。&lt;/p&gt;&#xA;&lt;h3 id=&#34;应用层之外&#34;&gt;应用层之外&lt;/h3&gt;&#xA;&lt;p&gt;前面的模型多是针对应用层的C10K类问题的解决方案，在更高并发要求的环境下就需要在内核态下做手脚了，比如使用零拷贝等技术，直接越过内核协议栈，实现高速数据包的传递，相应的内核模块也早有实现。主要的技术点在于：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;数据平面与控制平面分离，减少不必要的系统调用&lt;/li&gt;&#xA;&lt;li&gt;用户态驱动uio/vfio等减少内存拷贝&lt;/li&gt;&#xA;&lt;li&gt;使用内存池减少内存分配&lt;/li&gt;&#xA;&lt;li&gt;通过CPU亲和性提高缓存命中率&lt;/li&gt;&#xA;&lt;li&gt;网卡多队列与poll模式充分利用多核&lt;/li&gt;&#xA;&lt;li&gt;batch syscall&lt;/li&gt;&#xA;&lt;li&gt;用户态协议栈&lt;/li&gt;&#xA;&lt;li&gt;&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;相应的技术方案大多数是围绕这些点来做优化结合的。比如OSDI &amp;lsquo;14上的Arrakis、IX，再早的有pfring、netmap、intel DPDK、mTCP等等。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
