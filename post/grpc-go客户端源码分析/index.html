<!DOCTYPE html>
<html lang="en-us">
	<head>
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="author" content="feilengcui008">
<meta name="generator" content="Hugo 0.90.0-DEV" />
<title>gRPC-Go客户端源码分析</title>
<link rel="shortcut icon" href="https://feilengcui008.github.io/images/favicon.ico">
<link rel="stylesheet" href="https://feilengcui008.github.io/css/styles.css">
<link rel="stylesheet" href="https://feilengcui008.github.io/css/main.css">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/darcula.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  </head>
  <body>
    <nav class="main-nav">

    <div class="sidebar-toggle-parent" onmouseover="mouseOver()" onmouseout="mouseOut()">
        <div class="sidebar-toggle">
            <a href="/"><span class="icon icon-home dot"></span></a>
        </div>

        

        

        

        

        

        
        <div class="sidebar-toggle">
            <a href="/about"><span class="icon icon-user dot"></span></a>
        </div>
        

    </div>

</nav>

    <section id="wrapper">
        
        
<div class="content content-post CENTER">
  <article id="gRPC-Go客户端源码分析" class="article article-type-post" itemprop="blogPost">
  <header class="article-header">
    <h1 class="post-title">gRPC-Go客户端源码分析</h1>

    <div class="article-meta">
      <p>
      <span>
        <i class="icon-calendar"></i>
        <span>04-24-2017</span>
      </span>
      </p>
      <span>
        
        <span class="article-meta-span"><a href="/categories/%E5%9F%BA%E7%A1%80%E6%8A%80%E6%9C%AF">基础技术</a></span>
        
      </span>
      
        | 
      
      <span>
        
        <span class="article-meta-span"><a href="/tags/rpc">RPC</a></span>
        
      </span>
      <span id="/post/grpc-go%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" class="leancloud_visitors" data-flag-title="gRPC-Go客户端源码分析">
        <span class="post-flag"><span>
      </span>
    </div>
  </header>

  <div class="article-content">
    <h2 id="基本设计">基本设计</h2>
<p>gRPC-Go客户端的逻辑相对比较简单，从前面服务端的逻辑我们知道，客户端会通过http2复用tcp连接，每一次请求的调用基本上就是在已经建立好的tcp连接(并用ClientTransport抽象)上发送http请求，通过帧和流与服务端交互数据。</p>
<p>另外，一个服务对应的具体地址可能有多个，grpc在这里抽象了负载均衡的接口和部分实现。grpc提供两种负载均衡方式，一种是客户端内部自带的策略实现(目前只实现了轮询方式)，另一种方式是外部的load balancer。</p>
<ul>
<li>内部自带的策略实现: 这种方式主要针对一些简单的负载均衡策略比如轮询。轮询的实现逻辑是建立连接时通过定义的服务地址解析接口Resolver得到服务的地址列表，并单独用goroutine负责更新保持可用的连接，Watcher定义了具体更新实现的接口(比如多长时间解析更新一次)，最终在请求调用时会从可用连接列表中轮询选择其中一个连接发送请求。所以，grpc的负载均衡策略是请求级别的而不是连接级别的。</li>
<li>外部load balancer：这种方式主要针对 较复杂的负载均衡策略。grpclb实现了grpc这边的逻辑，并用protobuf定义了与load balancer交互的接口。gRPC-Go客户端建立连接时，会先与load balancer建立连接，并使用和轮询方式类似的Resolver、Watcher接口来更新load balancer的可用连接列表，不同的是每次load balancer连接变化时，会像load balancer地址发送rpc请求得到服务的地址列表。</li>
</ul>
<hr>
<h2 id="客户端主要流程">客户端主要流程</h2>
<p>客户端的逻辑主要可分为下面两部分:</p>
<ul>
<li>建立连接</li>
<li>请求调用、发送与响应</li>
</ul>
<h3 id="1-建立连接">1. 建立连接</h3>
<ul>
<li>典型的步骤</li>
</ul>
<pre tabindex="0"><code>func main() {
  // 建立连接
  conn, err := grpc.Dial(address, grpc.WithInsecure())
  c := pb.NewGreeterClient(conn)
  // 请求调用
  r, err := c.SayHello(context.Background(), &amp;pb.HelloRequest{Name: name})
  // 处理返回r
  // 对于单次请求，grpc直接负责返回响应数据
  // 对于流式请求，grpc会返回一个流的封装，由开发者负责流中数据的读写
}
</code></pre><ul>
<li>建立tcp(http2)连接</li>
</ul>
<pre tabindex="0"><code>func Dial(target string, opts ...DialOption) (*ClientConn, error) {
  return DialContext(context.Background(), target, opts...)
}
func DialContext(ctx context.Context, target string, opts ...DialOption) (conn *ClientConn, err error) {
  cc := &amp;ClientConn{
    target: target,
    conns:  make(map[Address]*addrConn),
  }
  /* ... */

  // 底层dialer，负责解析地址和建立tcp连接
  if cc.dopts.copts.Dialer == nil {
    cc.dopts.copts.Dialer = newProxyDialer(
      func(ctx context.Context, addr string) (net.Conn, error) {
        return dialContext(ctx, &quot;tcp&quot;, addr)
      },
    )
  }
  /* ... */

  if cc.dopts.scChan != nil {
    // Wait for the initial service config.
    select {
    case sc, ok := &lt;-cc.dopts.scChan:
      if ok {
        cc.sc = sc
      }
    case &lt;-ctx.Done():
      return nil, ctx.Err()
    }
  }
  /* ... */

  // 建立连接，如果设置了负载均衡，则通过负载均衡器建立连接
  // 否则直接连接
  waitC := make(chan error, 1)
  go func() {
    defer close(waitC)
    if cc.dopts.balancer == nil &amp;&amp; cc.sc.LB != nil {
      cc.dopts.balancer = cc.sc.LB
    }
    if cc.dopts.balancer != nil {
      var credsClone credentials.TransportCredentials
      if creds != nil {
        credsClone = creds.Clone()
      }
      config := BalancerConfig{
        DialCreds: credsClone,
      }
      // 负载均衡，可能是grcp-client内部的简单轮训负载均衡或者是外部的load balancer
      // 如果是外部的load balancer，这里的target是load balancer的服务名
      // grpclb会解析load balancer地址，建立rpc连接，得到服务地址列表，并通知Notify chan
      if err := cc.dopts.balancer.Start(target, config); err != nil {
        waitC &lt;- err
        return
      }
      // 更新后地址的发送channel
      ch := cc.dopts.balancer.Notify()
      if ch != nil {
        if cc.dopts.block {
          doneChan := make(chan struct{})
          // lbWatcher负责接收负载均衡器的地址更新，从而更新连接
          go cc.lbWatcher(doneChan)
          &lt;-doneChan
        } else {
          go cc.lbWatcher(nil)
        }
        return
      }
    }
    // 直接建立连接
    if err := cc.resetAddrConn(Address{Addr: target}, cc.dopts.block, nil); err != nil {
      waitC &lt;- err
      return
    }
  }()
  /* ... */
  if cc.dopts.scChan != nil {
    go cc.scWatcher()
  }

  return cc, nil
}
</code></pre><ul>
<li>内部负载均衡策略(轮询)，解析域名，并更新地址列表，写到Notify通知channel，由grpc的lbWatcher负责更新对应的服务连接列表</li>
</ul>
<pre tabindex="0"><code>func (rr *roundRobin) Start(target string, config BalancerConfig) error {
  /* ... */
  // 服务名解析，具体实现可以DNS或者基于etcd的服务发现等，每次解析会返回一个watcher
  // watcher具体服务解析请求的周期等
  w, err := rr.r.Resolve(target)
  if err != nil {
    return err
  }
  rr.w = w
  rr.addrCh = make(chan []Address)
  go func() {
    // 循环，不断解析服务的地址，更新对应的地址列表
    for {
      if err := rr.watchAddrUpdates(); err != nil {
        return
      }
    }
  }()
  return nil
}

func (rr *roundRobin) watchAddrUpdates() error {
  // 阻塞得到需要更新的地址列表，注意在naming里面的Resolver和Watcher
  // 定义了服务解析的接口，可以使用简单的dns解析实现、consul/etcd等服务发现
  // 以及其他形式，只要能返回对应的服务地址列表即可，Resolver里边缓存已经解析
  // 过的服务，并有单独的goroutine与后端服务通信更新，这样不用每次都解析地址
  updates, err := rr.w.Next()
  // 解析后，更新对应服务的地址列表，在内部做轮训负载均衡
  for _, update := range updates {
    addr := Address{
      Addr:     update.Addr,
      Metadata: update.Metadata,
    }
    switch update.Op {
    // 添加新地址
    case naming.Add:
      var exist bool
      for _, v := range rr.addrs {
        if addr == v.addr {
          exist = true
          grpclog.Println(&quot;grpc: The name resolver wanted to add an existing address: &quot;, addr)
          break
        }
      }
      if exist {
        continue
      }
      rr.addrs = append(rr.addrs, &amp;addrInfo{addr: addr})
      // 删除
    case naming.Delete:
      for i, v := range rr.addrs {
        if addr == v.addr {
          copy(rr.addrs[i:], rr.addrs[i+1:])
          rr.addrs = rr.addrs[:len(rr.addrs)-1]
          break
        }
      }
  }
  open := make([]Address, len(rr.addrs))
  for i, v := range rr.addrs {
    open[i] = v.addr
  }
  // 通知lbWatcher
  rr.addrCh &lt;- open
  return nil
}

// 轮询得到一个可用连接
func (rr *roundRobin) Get(ctx context.Context, opts BalancerGetOptions) (addr Address, put func(), err error) {
  /* ... */
  if len(rr.addrs) &gt; 0 {
    if rr.next &gt;= len(rr.addrs) {
      rr.next = 0
    }
    next := rr.next
    for {
      // 找到下一个，赋予返回值
      a := rr.addrs[next]
      next = (next + 1) % len(rr.addrs)
      if a.connected {
        addr = a.addr
        rr.next = next
        rr.mu.Unlock()
        return
      }
      if next == rr.next {
        // Has iterated all the possible address but none is connected.
        break
      }
    }
  }
  /* ... */
}
</code></pre><ul>
<li>外部负载均衡</li>
</ul>
<pre tabindex="0"><code>// 对于外部负载均衡，Start负责解析负载均衡器的地址列表
func (b *balancer) Start(target string, config grpc.BalancerConfig) error {
  /* ... */
  // 解析，返回watcher
  w, err := b.r.Resolve(target)
  b.w = w
  b.mu.Unlock()
  balancerAddrsCh := make(chan []remoteBalancerInfo, 1)
  go func() {
    for {
      // 一直循环解析load balancer的地址，一旦有更新则通知
      if err := b.watchAddrUpdates(w, balancerAddrsCh); err != nil {
        /* ... */
      }
    }
  }()
  go func() {
    var (
      cc *grpc.ClientConn
      // ccError is closed when there is an error in the current cc.
      // A new rb should be picked from rbs and connected.
      ccError chan struct{}
      rb      *remoteBalancerInfo
      rbs     []remoteBalancerInfo
      rbIdx   int
    )
    /* ... */
    for {
      var ok bool
      select {
      // 从channel中读取load balancer的列表
      case rbs, ok = &lt;-balancerAddrsCh:
        /* ... */
      }
      /* ... */
      // 连接load balancer
      if creds == nil {
        cc, err = grpc.Dial(rb.addr, grpc.WithInsecure())
      } else {
        /* ... */
        cc, err = grpc.Dial(rb.addr, grpc.WithTransportCredentials(creds))
      }
      b.mu.Lock()
      b.seq++ // tick when getting a new balancer address
      seq := b.seq
      b.next = 0
      b.mu.Unlock()
      // 对于每个load balancer的地址变化，获取新的服务地址列表，并通知lbWatcher更新
      go func(cc *grpc.ClientConn, ccError chan struct{}) {
        // load balancer client
        lbc := lbpb.NewLoadBalancerClient(cc)
        // 得到server list，并写入addrChan这个Notify channel
        b.callRemoteBalancer(lbc, seq)
        cc.Close()
        select {
        case &lt;-ccError:
        default:
          close(ccError)
        }
      }(cc, ccError)
    }
  }()
  return nil
}
</code></pre><h3 id="2-请求调用发送与响应">2. 请求调用、发送与响应</h3>
<pre tabindex="0"><code>// 单次请求，grpc负责invoke对应的服务方法，并直接返回数据
func (c *greeterClient) SayHello(ctx context.Context, in *HelloRequest, opts ...grpc.CallOption) (*HelloReply, error) {
  out := new(HelloReply)
  err := grpc.Invoke(ctx, &quot;/helloworld.Greeter/SayHello&quot;, in, out, c.cc, opts...)
  if err != nil {
    return nil, err
  }
  return out, nil
}

// 流式请求，grpc返回对应的流
func (c *routeGuideClient) ListFeatures(ctx context.Context, in *Rectangle, opts ...grpc.CallOption) (RouteGuide_ListFeaturesClient, error) {
  stream, err := grpc.NewClientStream(ctx, &amp;_RouteGuide_serviceDesc.Streams[0], c.cc, &quot;/routeguide.RouteGuide/ListFeatures&quot;, opts...)
  if err != nil {
    return nil, err
  }
  x := &amp;routeGuideListFeaturesClient{stream}
  if err := x.ClientStream.SendMsg(in); err != nil {
    return nil, err
  }
  if err := x.ClientStream.CloseSend(); err != nil {
    return nil, err
  }
  return x, nil
}

// 单次请求调用实现，响应返回时客户端会关闭流，而流式请求会直接将流封装后交给上层开发者，由开发者处理
func invoke(ctx context.Context, method string, args, reply interface{}, cc *ClientConn, opts ...CallOption) (e error) {
  /* ... */
  for {
    var (
      err    error
      t      transport.ClientTransport
      stream *transport.Stream
      // Record the put handler from Balancer.Get(...). It is called once the
      // RPC has completed or failed.
      put func()
    )
    /* ... */
    // 得到一个tcp连接(ClientTransport)
    t, put, err = cc.getTransport(ctx, gopts)
    /* ... */
    // 发送请求，打开新的流，序列化压缩请求数据，写入流
    stream, err = sendRequest(ctx, cc.dopts, cc.dopts.cp, callHdr, t, args, topts)
    /* ... */
    // 接收响应，解压反序列化响应，并写入reply
    err = recvResponse(ctx, cc.dopts, t, &amp;c, stream, reply)
    /* ... */
    // 关闭流
    t.CloseStream(stream, nil)
    if put != nil {
      put()
      put = nil
    }
    return stream.Status().Err()
  }
}

// 发送请求，打开一个新的流
func sendRequest(ctx context.Context, dopts dialOptions, compressor Compressor, callHdr *transport.CallHdr, t transport.ClientTransport, args interface{}, opts *transport.Options) (_ *transport.Stream, err error) {
  // 在此连接上打开新的流
  stream, err := t.NewStream(ctx, callHdr)
  if err != nil {
    return nil, err
  }
  /* ... */
  // 序列化压缩数据
  outBuf, err := encode(dopts.codec, args, compressor, cbuf, outPayload)
  // 写入流
  err = t.Write(stream, outBuf, opts)
  /* ... */
  // Sent successfully.
  return stream, nil
}

</code></pre><hr>
<h2 id="总结">总结</h2>
<p>至此，gRPC-Go的客户端逻辑主体部分分析完了，其中比较重要的是:</p>
<ul>
<li>连接的建立和负载均衡的实现</li>
<li>单次请求和流式请求的客户端实现区别</li>
<li>针对每一个连接客户端都会新建一个ClientTransport(具体实现为htt2client)，对应于服务端的ServerTransport(具体实现为http2server)，请求的发送和响应，流和帧数据的交互，以及流量控制等都由Transport这个概念来统筹。这里的Transport与Go的net/http标准库有些不同，Go中net/http的RoundTripper接口(及其实现http.Transport)底层可以管理多个tcp连接，而gRPC-Go中的Transport抽象是一个连接对应一个Transport。</li>
</ul>

  </div>
</article>


</div>
<div class="fexo-comments comments-post">
  <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "feilengcui008" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div> 



        <footer id="footer">
</footer>

    </section>
    <script src="https://feilengcui008.github.io/js/scroll-spy.js"></script>
<script src="https://feilengcui008.github.io/js/head.js"></script>
<script src="https://feilengcui008.github.io/js/bundle.js"></script>
<script src="https://feilengcui008.github.io/js/fastclick.js"></script>
<script src="https://feilengcui008.github.io/js/util.js"></script>
<script src="https://feilengcui008.github.io/js/zenscroll.js"></script>
<script src="https://feilengcui008.github.io/js/app.js"></script>
<script src="https://feilengcui008.github.io/js/jquery-3.2.1.min.js"></script>
<script src="https://feilengcui008.github.io/js/av-core-mini-0.6.1.js"></script>



<script>
    AV.initialize("sKCGt9cqaRvCq8ij2XsSRQET-gzGzoHsz", "Uusqiv2yEoQBC0vy7KnlzCqI");
</script>
<script>
    function showTime(Counter) {
        var query = new AV.Query(Counter);
        var entries = [];
        var $visitors = $(".leancloud_visitors");

        $visitors.each(function () {
            entries.push( $(this).attr("id").trim() );
        });

        query.containedIn('url', entries);
        query.find()
        .done(function (results) {
            var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

            if (results.length === 0) {
                $visitors.find(COUNT_CONTAINER_REF).text(0);
                return;
            }

            for (var i = 0; i < results.length; i++) {
                var item = results[i];
                var url = item.get('url');
                var time = item.get('time');
                var element = document.getElementById(url);

                $(element).find(COUNT_CONTAINER_REF).text(" - " + time);
            }
        })
        .fail(function (object, error) {
            console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
        var $visitors = $(".leancloud_visitors");
        var url = $visitors.attr('id').trim();
        var title = $visitors.attr('data-flag-title').trim();
        var query = new AV.Query(Counter);

        query.equalTo("url", url);
        query.find({
                success: function(results) {
                    if (results.length > 0) {
                        var counter = results[0];
                        counter.fetchWhenSave(true);
                        counter.increment("time");
                        counter.save(null, {
                                success: function(counter) {
                                    var $element = $(document.getElementById(url));
                                    $element.find('.leancloud-visitors-count').text(counter.get('time'));
                                },
                                error: function(counter, error) {
                                    console.log('Failed to save Visitor num, with error message: ' + error.message);
                                }
                        });
                    } else {
                        var newcounter = new Counter();
                         
                        var acl = new AV.ACL();
                        acl.setPublicReadAccess(true);
                        acl.setPublicWriteAccess(true);
                        newcounter.setACL(acl);
                         
                        newcounter.set("title", title);
                        newcounter.set("url", url);
                        newcounter.set("time", 1);
                        newcounter.save(null, {
                            success: function(newcounter) {
                                var $element = $(document.getElementById(url));
                                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
                            },
                            error: function(newcounter, error) {
                                console.log('Failed to create');
                            }
                        });
                    }
                },
                error: function(error) {
                    console.log('Error:' + error.code + " " + error.message);
                }
        });
    }

    $(function() {
        var Counter = AV.Object.extend("Counter");
        if ($('.post-list-flag').length > 0) {
            showTime(Counter);
        }
        if ($('.post-flag').length > 0) {
            addCount(Counter);
        }
    });
</script>

  </body>
</html>
